{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# STARGA: Unsupervised Spatialâ€“Temporal Augmentation in Rare-event Detection with Generative Models\n",
    "\n",
    "\n",
    "# ðŸ“Œ Introduction\n",
    "This notebook implements a STARGA framework for video anomaly detection. \n",
    "The architecture consists of two generators and two discriminators: \n",
    "## Generators:\n",
    "- **SpatialGenerator:** Obtained via segmentation (using GrabCut) and edge detection, this highlights object boundaries and structure. This parallels the role of the SpatialContextGenerator, which is tasked with producing realistic edge maps.\n",
    "- **TemporalGenerator:** Derived from frame differencing and smoothing, this captures the dynamics of moving objects. It is similar to how the TemporalPatternGenerator in STARGA learns the evolution of frame differences across a sequence.\n",
    "## Discriminators:\n",
    "Each generator has a corresponding discriminator to evaluate the realism of its outputs:\n",
    "\n",
    "- **SpatialDiscriminator:** assesses the realism of the edge-like images produced by the SpatialContextGenerator.\n",
    "- **TemporalDiscriminator:** evaluates the generated temporal dynamics, ensuring they align with genuine motion patterns observed in video sequences.\n",
    "- \n",
    "By leveraging these dual pathwaysâ€”one for spatial context and one for temporal patternsâ€”the STARGA framework can effectively detect anomalies in videos by comparing the generated representations with the actual preprocessed data derived from techniques like frame differencing, smoothing, segmentation, and edge detection.\n",
    "\n",
    "\n",
    "The following cells write each module to disk and then run the training (or evaluation) procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš™ï¸ Configuration Module Overview\n",
    "This module sets up essential configurations for training and testing, including directory creation, shared settings, and utility functions for converting configuration dictionaries into class attributes.\n",
    "\n",
    "## Directory Setup:\n",
    "Checks for and creates the weights and results/ped2 directories if they do not exist.\n",
    "\n",
    "## Shared Configuration:\n",
    "Uses a dictionary (share_config) to store common settings such as mode, dataset, and img_size.\n",
    "\n",
    "## Dictionary-to-Class Conversion:\n",
    "The dict2class class converts the configuration dictionary into an object with attribute-style access, making it easy to print and access configuration values.\n",
    "\n",
    "## Configuration Update:\n",
    "The update_config function modifies the shared configuration based on input arguments and mode (train or test), ensuring that paths and parameters are set appropriately depending on whether the code runs locally or on Kaggle.\n",
    "\n",
    "## Boolean Conversion Utility:\n",
    "The str2bool function converts string inputs into boolean values for command-line argument parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:04.316590Z",
     "iopub.status.busy": "2025-04-19T06:01:04.316288Z",
     "iopub.status.idle": "2025-04-19T06:01:04.323064Z",
     "shell.execute_reply": "2025-04-19T06:01:04.322297Z",
     "shell.execute_reply.started": "2025-04-19T06:01:04.316566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.py\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists('weights'):\n",
    "    os.mkdir('weights')\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "if not os.path.exists('results/ped2'):\n",
    "    os.mkdir('results/ped2')\n",
    "\n",
    "\n",
    "share_config = {'mode': 'training',\n",
    "                'dataset': 'ped2',\n",
    "                'img_size': (256, 256)\n",
    "}\n",
    "\n",
    "class dict2class:\n",
    "    def __init__(self, config):\n",
    "        for k, v in config.items():\n",
    "            self.__setattr__(k, v)\n",
    "\n",
    "    def print_cfg(self):\n",
    "        print('\\n' + '-' * 30 + f'{self.mode} cfg' + '-' * 30)\n",
    "        for k, v in vars(self).items():\n",
    "            print(f'{k}: {v}')\n",
    "        print()\n",
    "\n",
    "\n",
    "def update_config(args=None, mode=None):\n",
    "    share_config['mode'] = mode\n",
    "    share_config['dataset'] = args.dataset\n",
    "    \n",
    "    if args.is_local:\n",
    "        share_config['root_folder'] = ''\n",
    "    else:\n",
    "        share_config['root_folder'] = '/kaggle/input/ped2-v1/' \n",
    "    root_folder=share_config['root_folder'] \n",
    "\n",
    "    if mode == 'train':\n",
    "        share_config['batch_size'] = args.batch_size\n",
    "        share_config['train_data'] =   share_config['root_folder']    + args.dataset + '/training/frames/'\n",
    "        share_config['test_root_path'] =   share_config['root_folder']   + args.dataset + '/testing/'\n",
    "        share_config['train_root_path'] =   share_config['root_folder']   + args.dataset + '/training/'\n",
    "        share_config['test_data'] =  share_config['root_folder']  + args.dataset + '/testing/frames/'\n",
    "        share_config['g_lr'] = 0.0002\n",
    "        share_config['d_lr'] = 0.00002\n",
    "        share_config['show_flow'] = args.show_flow\n",
    "        share_config['resume'] = args.resume if args.resume else None\n",
    "        share_config['save_interval'] = args.save_interval\n",
    "        share_config['val_interval'] = args.val_interval\n",
    "        share_config['manualseed'] = args.manualseed\n",
    "        share_config['generator_iters'] = args.generator_iters\n",
    "        share_config['cuda'] = args.cuda\n",
    "        share_config['is_local'] = args.is_local\n",
    "\n",
    "    elif mode == 'test':\n",
    "        share_config['test_data'] = share_config['root_folder']    + args.dataset + '/testing/frames/'\n",
    "        share_config['test_root_path'] =   share_config['root_folder']  + args.dataset + '/testing/'\n",
    "        \n",
    "        share_config['trained_model'] = args.trained_model\n",
    "        share_config['show_curve'] = args.show_curve\n",
    "        share_config['show_heatmap'] = args.show_heatmap\n",
    "        share_config['generator_iters'] = args.generator_iters\n",
    "        share_config['resume'] =args.resume\n",
    "        share_config['cuda'] = args.cuda\n",
    "        \n",
    "        share_config['manualseed'] = args.manualseed\n",
    "        share_config['batch_size'] = args.batch_size\n",
    "        share_config['is_local'] = args.is_local\n",
    "    return dict2class(share_config)  # change dict keys to class attributes\n",
    "\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ Dataset Module Overview\n",
    "This module handles all aspects of video data loading, preprocessing, and organization for anomaly detection tasks. It provides helper functions for image processing and defines custom dataset classes for training and testing, ensuring data is efficiently prepared for use with PyTorch models.\n",
    "## Helper Functions:\n",
    "\n",
    "ðŸ–¼ï¸ np_load_frame: Loads an image from disk, applies transformations, resizes, normalizes pixel values to [-1, 1], and formats it to (C, H, W) for PyTorch.\n",
    "\n",
    "âš¡ attention_canny_edge_detection: Uses Canny edge detection, modulated by an attention map based on the difference between a frame and its background, to produce enhanced edge images.\n",
    "\n",
    "ðŸ”„ apply_frame_differencing: Implements background subtraction by computing the absolute difference between a frame and a background, normalizing and formatting the result.\n",
    "\n",
    "ðŸ”€ load_frame_all_types: Simultaneously loads the original image, frame difference image, and edge image, ensuring all are resized, normalized, and formatted correctly.\n",
    "\n",
    "## Video Data Structure:\n",
    "\n",
    "ðŸ“¦ VideoObject: A simple class to encapsulate all related information for a video, including the background frame, lists of frame paths, edge frame paths, frame difference paths, video ID, and total number of frames.\n",
    "\n",
    "## Custom Dataset Classes:\n",
    "\n",
    "ðŸš€ train_dataset: Organizes training data by extracting video sequences with a specified length and overlap. It also handles background extraction (using average or median frames) and converts frames into PyTorch tensors for training.\n",
    "\n",
    "ðŸ” test_dataset: Similar to train_dataset, but specifically tailored for testing data. It processes video sequences and loads them in a format suitable for inference.\n",
    "\n",
    "ðŸ“Š Label_loader: Loads ground truth labels from MATLAB files for the UCSD Ped2 dataset, mapping abnormal events to frame-level labels and preparing them in sequences that align with the video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:05.218363Z",
     "iopub.status.busy": "2025-04-19T06:01:05.218080Z",
     "iopub.status.idle": "2025-04-19T06:01:05.226612Z",
     "shell.execute_reply": "2025-04-19T06:01:05.225623Z",
     "shell.execute_reply.started": "2025-04-19T06:01:05.218342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import scipy.io as scio\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from numpy import array, uint8\n",
    "\n",
    "\n",
    "\n",
    "def np_load_frame(filename, resize_h, resize_w, transform=None):\n",
    "    img = cv2.imread(filename)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Error: Unable to load image {filename}\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "    if transform:\n",
    "        img = Image.fromarray(img)  # Convert to PIL image\n",
    "        img = transform(img)        # Apply transform\n",
    "        img = np.array(img)         # Convert back to numpy array\n",
    "\n",
    "    img_resized = cv2.resize(img, (resize_w, resize_h), interpolation=cv2.INTER_LINEAR).astype('float32')\n",
    "    img_resized = (img_resized / 127.5) - 1.0  # Normalize to range [-1, 1]\n",
    "    \n",
    "    if img_resized.ndim == 2:  # Handle grayscale images\n",
    "        img_resized = np.expand_dims(img_resized, axis=-1)\n",
    "\n",
    "    img_resized = np.transpose(img_resized, (2, 0, 1))  # Convert to (C, H, W)\n",
    "    \n",
    "    return img_resized\n",
    "def attention_canny_edge_detection(frame, background_frame):\n",
    "    \"\"\"\n",
    "    Applies Canny edge detection and modulates it using an attention map.\n",
    "    \n",
    "    Parameters:\n",
    "        frame (numpy.ndarray): Input Sequence of frames (e.g., video frame).\n",
    "        median_frame (numpy.ndarray): Median frame used for attention modulation.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Edge-detected image of shape (240, 360, 1).\n",
    "    \"\"\"\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = cv2.normalize(frame, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    if background_frame.dtype != np.uint8:\n",
    "        background_frame = cv2.normalize(background_frame, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Step 1: Apply Canny Edge Detection\n",
    "    canny_edges = cv2.Canny(image, 100, 200)\n",
    "\n",
    "    # Step 2: Compute Attention Map\n",
    "    attention = cv2.cvtColor(frame - background_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize attention map to uint8 if needed\n",
    "    if attention.dtype != np.uint8:\n",
    "        attention = cv2.normalize(attention, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "\n",
    "    # Step 4: Modulate Canny Edges with Attention Map\n",
    "    enhanced_edges = cv2.bitwise_and(canny_edges, attention)\n",
    "    # Step 5: Reshape to (h, w, 1)\n",
    "    enhanced_edges = np.expand_dims(enhanced_edges, axis=-1)\n",
    "    enhanced_edges = np.transpose(enhanced_edges, (2, 0, 1))\n",
    "    return enhanced_edges  # Shape: (h, w, 1)\n",
    "def apply_frame_differencing(frame,background):\n",
    "    \"\"\"Applies simple frame differencing for background subtraction.\"\"\"\n",
    "    # background = frames[0]  # Use the first frame as reference\n",
    "    \n",
    "    fg_mask = cv2.absdiff(frame, background.astype(np.float32))  # Difference between first and second frame\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    \n",
    "    fg_mask = (fg_mask / 127.5) - 1.0  # Normalize to range [-1, 1]\n",
    "    \n",
    "    fg_mask = np.transpose(fg_mask, ( 2, 0,1))\n",
    "         \n",
    "    return fg_mask\n",
    "\n",
    "def load_frame_all_types(filename, resize_h, resize_w,edge_frame_path, diff_frame_path):\n",
    "    # âœ… Load images\n",
    "    img = cv2.imread(filename)\n",
    "    diff_frame = cv2.imread(diff_frame_path)\n",
    "    edge_frame = cv2.imread(edge_frame_path, cv2.IMREAD_GRAYSCALE)  # Ensure grayscale\n",
    "    if img is None or diff_frame is None or edge_frame is None:\n",
    "        raise FileNotFoundError(f\"Error: Unable to load one of the images!\")\n",
    "\n",
    "    # âœ… Resize images\n",
    "    img_resized = cv2.resize(img, (resize_w, resize_h), interpolation=cv2.INTER_LINEAR).astype(np.float32)\n",
    "    diff_frame_resized = cv2.resize(diff_frame, (resize_w, resize_h), interpolation=cv2.INTER_LINEAR).astype(np.float32)\n",
    "    edge_frame_resized = cv2.resize(edge_frame, (resize_w, resize_h), interpolation=cv2.INTER_LINEAR).astype(np.float32)\n",
    "\n",
    "    # âœ… Convert RGB images from BGR â†’ RGB\n",
    "    img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    diff_frame_resized = cv2.cvtColor(diff_frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # âœ… Normalize images to range [-1, 1]\n",
    "    img_resized = (img_resized / 127.5) - 1.0\n",
    "    diff_frame_resized = (diff_frame_resized / 127.5) - 1.0\n",
    "    edge_frame_resized = (edge_frame_resized / 127.5) - 1.0  # Grayscale normalization\n",
    "   \n",
    "    # âœ… Ensure grayscale has the correct dimensions (1, H, W) instead of (H, W)\n",
    "    edge_frame_resized = np.expand_dims(edge_frame_resized, axis=0)  # Ensure (1, H, W)\n",
    "    \n",
    "    if img_resized.ndim == 2:  # Handle grayscale images\n",
    "        img_resized = np.expand_dims(img_resized, axis=-1)\n",
    "    # âœ… Ensure RGB images are in (C, H, W) format\n",
    "    img_resized = np.transpose(img_resized, (2, 0, 1))  # Convert (H, W, C) â†’ (C, H, W)\n",
    "    diff_frame_resized = np.transpose(diff_frame_resized, (2, 0, 1))  # Convert (H, W, C) â†’ (C, H, W)\n",
    "    \n",
    "\n",
    "    return img_resized, diff_frame_resized,edge_frame_resized\n",
    "# def load_frame_all_types(filename, resize_h, resize_w, background_path):\n",
    "#     img = cv2.imread(filename)\n",
    "#     background = cv2.imread(background_path)\n",
    "#     if img is None:\n",
    "#         raise FileNotFoundError(f\"Error: Unable to load image {filename}\")\n",
    "#     #background = cv2.cvtColor(background, cv2.COLOR_RGB2BGR)\n",
    "#     img_resized = cv2.resize(img, (resize_w, resize_h), interpolation=cv2.INTER_LINEAR).astype('float32')\n",
    "    \n",
    "#     diff_frame = apply_frame_differencing(img_resized, background)\n",
    "#     edge_frame = attention_canny_edge_detection(img_resized, background)\n",
    "#     img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "     \n",
    "\n",
    "#     img_resized = (img_resized / 127.5) - 1.0  # Normalize to range [-1, 1]\n",
    "    \n",
    "#     if img_resized.ndim == 2:  # Handle grayscale images\n",
    "#         img_resized = np.expand_dims(img_resized, axis=-1)\n",
    "    \n",
    "#     img_resized = np.transpose(img_resized, (2, 0, 1))  # Convert to (C, H, W)\n",
    "    \n",
    "\n",
    "#     return img_resized, diff_frame,edge_frame\n",
    "\n",
    "class VideoObject(object):\n",
    "    def __init__(self, background_image,frame_list,edge_list, diff_frame_list,video_id,frame_length):\n",
    "        self.background_image = background_image\n",
    "        self.frame_list = frame_list\n",
    "        self.edge_list = edge_list\n",
    "        self.diff_frame_list = diff_frame_list\n",
    "        self.video_id = video_id\n",
    "        self.num_frames = frame_length\n",
    "class train_dataset(Dataset):\n",
    "    def __init__(self, cfg, seq_len=10, overlap=10, transform=None):\n",
    "        self.img_h = cfg.img_size[0]\n",
    "        self.img_w = cfg.img_size[1]\n",
    "        self.seq_len =seq_len\n",
    "        self.overlap =overlap\n",
    "        vids = [d for d in os.listdir(cfg.train_data) if os.path.isdir(os.path.join(cfg.train_data, d))]\n",
    "        self.transform = transform\n",
    "        self.videos = []\n",
    "        self.train_path=cfg.train_data\n",
    "\n",
    "        for d in vids:\n",
    "            video_dir = os.path.join(cfg.train_data+'/', d)\n",
    "            edge_dir = os.path.join(cfg.train_root_path+'/spatial_frames/', d)\n",
    "            diff_frame_dir = os.path.join(cfg.train_root_path+'/temporal_frames/', d)\n",
    "            background_image = self.background_extract(video_dir,d)\n",
    "            num_frames = len([name for name in os.listdir(video_dir) if os.path.isfile(os.path.join(video_dir, name)) and (name.endswith('.jpg') or name.endswith('.png'))])\n",
    "            for i in range(0, num_frames, self.overlap):\n",
    "                if i + self.seq_len  > num_frames:\n",
    "                    break\n",
    "                frames =[]\n",
    "                edge_frames =[]\n",
    "                diff_frames =[]\n",
    "                for j in range(i, i + self.seq_len):\n",
    "                    frames.append(os.path.join(video_dir, '{0:03d}.jpg'.format(j)))\n",
    "                    edge_frames.append(os.path.join(edge_dir, '{0:03d}.png'.format(j)))\n",
    "                    diff_frames.append(os.path.join(diff_frame_dir, '{0:03d}.png'.format(j)))\n",
    "                self.videos.append(VideoObject(background_image,frames,edge_frames,diff_frames,d,num_frames))\n",
    "    def background_extract(self,video_dir,index):\n",
    "        if  os.path.exists(os.path.join(self.train_path, str(index)+'average_frame.png')):\n",
    "            avg_frame =np_load_frame(os.path.join(self.train_path, str(index)+'average_frame.png'), self.img_h, self.img_w,None)\n",
    "        else:\n",
    "            num_frames = len([name for name in os.listdir(video_dir) if os.path.isfile(os.path.join(video_dir, name)) and (name.endswith('.jpg') or name.endswith('.png'))])\n",
    "            video_clip =[]\n",
    "            for i in range(0, num_frames):  \n",
    "                video_clip.append(np_load_frame(os.path.join(video_dir, '{0:03d}.jpg'.format(i)), self.img_h, self.img_w,None))\n",
    "            avg_frame = self.compute_average_frame(np.array(video_clip))\n",
    "            save_image(((torch.from_numpy(avg_frame) + 1 ) )[(2,1,0),...] , os.path.join(self.train_path,str(index)+'average_frame.png'))\n",
    "        return avg_frame\n",
    "    def compute_average_frame(self,frames):\n",
    "        \"\"\"Computes the average frame.\"\"\"\n",
    "        avg_frame = np.mean(frames, axis=0)\n",
    "        return avg_frame.astype('float32')\n",
    "\n",
    "\n",
    "    def compute_median_frame(self,frames):\n",
    "        \"\"\"Computes the median frame.\"\"\"\n",
    "        median_frame = np.median(frames, axis=0)\n",
    "        return median_frame.astype('float32')\n",
    " \n",
    "    def __len__(self):  # This decide the indice range of the PyTorch Dataloader.\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, indice):  # Indice decide which video folder to be loaded.\n",
    "        one_folder = self.videos[indice]\n",
    "        video_clip = []\n",
    "        diff_frames = []\n",
    "        edge_frames = []\n",
    "        start = 0  # Always use the last index in self.all_seqs.\n",
    "        for i in range(start, len(one_folder.frame_list)):\n",
    "            # image = Image.open(one_folder[i])\n",
    "               \n",
    "            image, diff_frame, edge_frame= load_frame_all_types(one_folder.frame_list[i], self.img_h, self.img_w, one_folder.edge_list[i],one_folder.diff_frame_list[i])\n",
    "            # image= np_load_frame(one_folder.frame_list[i], self.img_h, self.img_w, self.transform)\n",
    "            video_clip.append(image)\n",
    "            diff_frames.append(diff_frame)\n",
    "            edge_frames.append(edge_frame)\n",
    "        # Stack frames to create a tensor of shape [num_frames, channels, height, width]\n",
    "          # Compute average, min, max, and median frames\n",
    "        \n",
    "        #median_frame = self.compute_median_frame(video_clip)\n",
    "    \n",
    "        # Save the computed frames\n",
    "        video_clip = np.array(video_clip)\n",
    "        video_clip = torch.from_numpy(video_clip)\n",
    "        diff_frames = np.array(diff_frames)\n",
    "        diff_frames = torch.from_numpy(diff_frames)\n",
    "        edge_frames = np.array(edge_frames)\n",
    "        edge_frames = torch.from_numpy(edge_frames)\n",
    "        return video_clip , diff_frames, edge_frames, one_folder.background_image,one_folder.video_id,one_folder.num_frames\n",
    "\n",
    "class test_dataset:\n",
    "    def __init__(self, cfg, seq_len=10, overlap=10, transform=None):\n",
    "        self.img_h = cfg.img_size[0]\n",
    "        self.img_w = cfg.img_size[1]\n",
    "        self.clip_length = 5\n",
    "        self.videos = []    \n",
    "        self.seq_len =seq_len\n",
    "        self.overlap =overlap\n",
    "        self.transform = transform\n",
    "        self.test_path = f'{cfg.root_folder}/{cfg.dataset}/testing/average_frames/'\n",
    "        vids = [d for d in os.listdir(cfg.test_data+'/') if os.path.isdir(os.path.join(cfg.test_data+'/', d))]\n",
    "        vids.sort()\n",
    "        for d in vids:\n",
    "            video_dir = os.path.join(cfg.test_data+'/', d)\n",
    "            edge_dir = os.path.join(cfg.test_root_path+'/spatial_frames/', d)\n",
    "            diff_frame_dir = os.path.join(cfg.test_root_path+'/temporal_frames/', d)\n",
    "           \n",
    "            background_image = self.background_extract(video_dir,d)\n",
    "            num_frames = len([name for name in os.listdir(video_dir) if os.path.isfile(os.path.join(video_dir, name)) and (name.endswith('.jpg') or name.endswith('.png'))])\n",
    "            for i in range(0, num_frames, self.overlap):\n",
    "                if i + self.seq_len  > num_frames:\n",
    "                    break\n",
    "                frames =[]\n",
    "                edge_frames =[]\n",
    "                diff_frames =[]\n",
    "                for j in range(i, i + self.seq_len):\n",
    "                    frames.append(os.path.join(video_dir, '{0:03d}.jpg'.format(j)))\n",
    "                    edge_frames.append(os.path.join(edge_dir, '{0:03d}.png'.format(j)))\n",
    "                    diff_frames.append(os.path.join(diff_frame_dir, '{0:03d}.png'.format(j)))\n",
    "                \n",
    "                self.videos.append(VideoObject(background_image,frames,edge_frames,diff_frames,d,num_frames))\n",
    "    def background_extract(self,video_dir,index):\n",
    "        if  os.path.exists(os.path.join(self.test_path, str(index)+'average_frame.png')):\n",
    "            avg_frame =np_load_frame(os.path.join(self.test_path, str(index)+'average_frame.png'), self.img_h, self.img_w,None)\n",
    "        else:\n",
    "            num_frames = len([name for name in os.listdir(video_dir) if os.path.isfile(os.path.join(video_dir, name)) and (name.endswith('.jpg') or name.endswith('.png'))])\n",
    "            video_clip =[]\n",
    "            for i in range(0, num_frames):  \n",
    "                video_clip.append(np_load_frame(os.path.join(video_dir, '{0:03d}.jpg'.format(i)), self.img_h, self.img_w,None))\n",
    "            avg_frame = self.compute_median_frame(np.array(video_clip))\n",
    "            save_image(((torch.from_numpy(avg_frame) + 1 ) )[(2,1,0),...] , os.path.join(self.test_path,str(index)+'average_frame.png'))\n",
    "        return avg_frame\n",
    "    def compute_average_frame(self,frames):\n",
    "        \"\"\"Computes the average frame.\"\"\"\n",
    "        avg_frame = np.mean(frames, axis=0)\n",
    "        return avg_frame.astype('float32')\n",
    "    def compute_median_frame(self,frames):\n",
    "        \"\"\"Computes the median frame.\"\"\"\n",
    "        median_frame = np.median(frames, axis=0)\n",
    "        return median_frame.astype('float32')\n",
    "    def __len__(self):\n",
    "        return len(self.videos)  # The first [input_num] frames are unpredictable.\n",
    "\n",
    "    def __getitem__(self, indice):\n",
    "        one_folder = self.videos[indice]\n",
    "        video_clips = []\n",
    "        diff_frames = []\n",
    "        edge_frames = []\n",
    "        for frame_id in range(0, len(one_folder.frame_list)):\n",
    "            image, diff_frame, edge_frame= load_frame_all_types(one_folder.frame_list[frame_id], self.img_h, self.img_w, one_folder.edge_list[frame_id],one_folder.diff_frame_list[frame_id] )\n",
    "           \n",
    "            video_clips.append(image)\n",
    "            \n",
    "            diff_frames.append(diff_frame)\n",
    "            edge_frames.append(edge_frame)\n",
    "         # Save the computed frames\n",
    "        # if  os.path.exists(os.path.join(self.test_path, str(indice)+'.png')):\n",
    "        #     avg_frame =np_load_frame(os.path.join(self.test_path, str(indice)+'.png'), self.img_h, self.img_w)\n",
    "        # else:\n",
    "        #     avg_frame = self.compute_average_frame(np.array(video_clips))\n",
    "           \n",
    "        #     save_image((torch.from_numpy(avg_frame) +1 )[(2,1,0),...] , os.path.join(self.test_path,str(indice)+'.png'))\n",
    "        \n",
    "        video_clips = np.array(video_clips) #.reshape((-1, self.img_h, self.img_w))\n",
    "        video_clips = torch.from_numpy(video_clips)\n",
    "        diff_frames = np.array(diff_frames)\n",
    "        diff_frames = torch.from_numpy(diff_frames)\n",
    "        edge_frames = np.array(edge_frames)\n",
    "        edge_frames = torch.from_numpy(edge_frames)\n",
    "        return video_clips , diff_frames, edge_frames,one_folder.background_image,one_folder.video_id,one_folder.num_frames\n",
    "    \n",
    "\n",
    "class Label_loader:\n",
    "    def __init__(self, cfg, video_folders, seq_len=10, overlap=10):\n",
    "        self.cfg = cfg\n",
    "        self.name = cfg.dataset\n",
    "        self.frame_path = cfg.test_data\n",
    "        self.mat_path = f'{cfg.root_folder}/{self.name}/{self. name}.mat'\n",
    "        self.video_folders = video_folders\n",
    "        \n",
    "        self.abnormal_events = array([ \n",
    "                array([ 61, 180], dtype=uint8),\n",
    "                array([ 95, 180], dtype=uint8),\n",
    "                array([  1, 146], dtype=uint8),\n",
    "                array([ 31, 180], dtype=uint8),\n",
    "                array([  1, 129], dtype=uint8),\n",
    "                array([  1, 159], dtype=uint8),\n",
    "                array([ 46, 180], dtype=uint8),\n",
    "                array([  1, 180], dtype=uint8),\n",
    "                array([  1, 120], dtype=uint8),\n",
    "                array([  1, 150], dtype=uint8),\n",
    "                array([  1, 180], dtype=uint8),\n",
    "                array([ 88, 180], dtype=uint8)\n",
    "            ], dtype=object)\n",
    "        # self.abnormal_events = scio.loadmat(self.mat_path, squeeze_me=True)['gt']\n",
    "        self.seq_len =seq_len\n",
    "        self.overlap =overlap\n",
    "       \n",
    "            \n",
    "\n",
    "    def __call__(self):\n",
    "        gt = self.load_ucsd_ped2()\n",
    "        return gt\n",
    "    \n",
    "    def load_ucsd_ped2(self):\n",
    "        frames_score =[]\n",
    "        for i in range(self.abnormal_events.shape[0]):\n",
    "            length = len(os.listdir(self.video_folders[i]))\n",
    "            sub_video_gt = np.zeros((length,), dtype=np.int8)\n",
    "\n",
    "            one_abnormal = self.abnormal_events[i]\n",
    "            if one_abnormal.ndim == 1:\n",
    "                one_abnormal = one_abnormal.reshape((one_abnormal.shape[0], -1))\n",
    "\n",
    "            for j in range(one_abnormal.shape[1]):\n",
    "                start = one_abnormal[0, j] - 1\n",
    "                end = one_abnormal[1, j]\n",
    "\n",
    "                sub_video_gt[start: end] = 1\n",
    "            for k in range(0, length, self.overlap):\n",
    "                if k + self.seq_len  > length:\n",
    "                    break\n",
    "                frames_score.append(sub_video_gt[k: k + self.seq_len])\n",
    "\n",
    "      \n",
    "\n",
    "        return frames_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Loss Module Overview\n",
    "This module defines multiple loss functions and utility classes for training the STARGA model in video anomaly detection. It encompasses losses for both the generator and discriminator networks, along with perceptual and gradient-based losses to guide the training process.\n",
    "\n",
    "## âš™ï¸ Utility Functions & Loss Components\n",
    "The Utility class encapsulates several static helper functions:\n",
    "\n",
    "SSIM Computation:\n",
    "Implements both a basic and a windowed version of the Structural Similarity Index (SSIM) to assess image similarity.\n",
    "\n",
    "Edge Consistency:\n",
    "Uses Sobel filters to extract edge maps and then computes a loss (using Smooth L1 loss) to ensure the edges of the generated images match those of the real images.\n",
    "\n",
    "Adaptive Generator Loss:\n",
    "Combines Energy-Based GAN loss and Relativistic Hinge Loss with adaptive weighting based on the discriminator outputs.\n",
    "\n",
    "ðŸ§  Perceptual Loss\n",
    "The PerceptualLoss class leverages a pretrained VGG19 network to extract high-level features from images. The loss is computed as the mean squared error (MSE) between features extracted from generated and target images, promoting the perceptual similarity of the outputs.\n",
    "\n",
    "## â³ Temporal & ðŸ–¼ï¸ Spatial Generator Losses\n",
    "These generator losses guide the generators to produce realistic temporal and spatial outputs:\n",
    "\n",
    "### TemporalGeneratorLoss:\n",
    "Combines adversarial (fooling) loss, perceptual loss, SSIM loss, edge consistency loss, and a feature-aware multi-scale gradient difference loss. Each component is weighted by a corresponding lambda factor to balance its impact on the overall loss.\n",
    "\n",
    "###  SpatialGeneratorLoss:\n",
    "Similar to the temporal loss but tailored for spatial outputs (e.g., foreground edge images). It integrates adversarial loss, edge consistency, SSIM, and gradient difference losses.\n",
    "\n",
    "## â¹ Temporal & ðŸ“ Spatial Discriminator Losses\n",
    "Discriminator losses are designed to penalize the network when it fails to distinguish between real and fake images, with added adaptive penalties:\n",
    "\n",
    "### TemporalDiscriminatorLoss:\n",
    "Combines a relativistic hinge loss (with adaptive components) and a multi-scale penalty that leverages a pretrained VGG19 network. It also computes an adaptive gradient penalty based on training progress.\n",
    "\n",
    "### SpatialDiscriminatorLoss:\n",
    "Implements a similar adaptive hinge loss and gradient penalty for spatial discriminator training. It further includes a contrastive penalty based on feature distances to enforce consistency in the feature space.\n",
    "\n",
    "## ðŸ” Feature-Aware Multi-Scale GDLoss\n",
    "The FeatureAwareMultiScaleGDLoss (FA-EM-GDL) is a specialized loss that:\n",
    "\n",
    "Uses Sobel filters to compute image gradients and derive an edge-aware weight map.\n",
    "\n",
    "Computes differences in gradients and leverages features from early layers of a pretrained VGG19 network.\n",
    "\n",
    "Integrates these multi-scale differences (both edge and feature based) to produce a loss that captures fine-grained differences between generated and ground truth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:05.363988Z",
     "iopub.status.busy": "2025-04-19T06:01:05.363539Z",
     "iopub.status.idle": "2025-04-19T06:01:05.374938Z",
     "shell.execute_reply": "2025-04-19T06:01:05.374042Z",
     "shell.execute_reply.started": "2025-04-19T06:01:05.363946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing loss.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile loss.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Utility:\n",
    "    @staticmethod\n",
    "    def ssim(img1, img2):\n",
    "        mu1, mu2 = torch.mean(img1, dim=(2, 3)), torch.mean(img2, dim=(2, 3))\n",
    "        sigma1, sigma2 = torch.var(img1, dim=(2, 3)), torch.var(img2, dim=(2, 3))\n",
    "        covariance = torch.mean((img1 - mu1.unsqueeze(-1).unsqueeze(-1)) * (img2 - mu2.unsqueeze(-1).unsqueeze(-1)), dim=(2, 3))\n",
    "        c1, c2 = 1e-4, 9e-4\n",
    "        ssim = ((2 * mu1 * mu2 + c1) * (2 * covariance + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1 + sigma2 + c2))\n",
    "        return torch.mean(ssim)\n",
    "    @staticmethod\n",
    "    def gaussian_window(window_size: int, sigma: float) -> torch.Tensor:\n",
    "        gauss = torch.Tensor([np.exp(-(x - window_size//2)**2/(2*sigma**2)) for x in range(window_size)])\n",
    "        window = gauss.unsqueeze(1) * gauss.unsqueeze(0)\n",
    "        return window / window.sum()\n",
    "\n",
    "    def ssim_windowed(img1: torch.Tensor, img2: torch.Tensor, window_size: int = 11, sigma: float = 1.5, size_average: bool = True) -> torch.Tensor:\n",
    "        assert img1.shape == img2.shape, \"Input images must have the same dimensions.\"\n",
    "        device = img1.device\n",
    "        channel = img1.size(1)\n",
    "        window = Utility.gaussian_window(window_size, sigma).to(device)\n",
    "        window = window.unsqueeze(0).unsqueeze(0)\n",
    "        window = window.expand(channel, 1, window_size, window_size)\n",
    "        padding = window_size // 2\n",
    "        mu1 = F.conv2d(img1, window, padding=padding, groups=channel)\n",
    "        mu2 = F.conv2d(img2, window, padding=padding, groups=channel)\n",
    "        mu1_sq = mu1 ** 2\n",
    "        mu2_sq = mu2 ** 2\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        sigma1_sq = F.conv2d(img1 * img1, window, padding=padding, groups=channel) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, window, padding=padding, groups=channel) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, window, padding=padding, groups=channel) - mu1_mu2\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        if size_average:\n",
    "            return ssim_map.mean()\n",
    "        else:\n",
    "            return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def edge_consistency(img1, img2):\n",
    "        sobel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32).view(1, 1, 3, 3).to(img1.device)\n",
    "        sobel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32).view(1, 1, 3, 3).to(img1.device)\n",
    "        img1_gray = torch.mean(img1, dim=1, keepdim=True)\n",
    "        img2_gray = torch.mean(img2, dim=1, keepdim=True)\n",
    "        edge1_x = F.conv2d(img1_gray, sobel_x, padding=1)\n",
    "        edge1_y = F.conv2d(img1_gray, sobel_y, padding=1)\n",
    "        edge2_x = F.conv2d(img2_gray, sobel_x, padding=1)\n",
    "        edge2_y = F.conv2d(img2_gray, sobel_y, padding=1)\n",
    "        epsilon = 1e-6\n",
    "        edge1 = torch.sqrt(torch.clamp(edge1_x**2 + edge1_y**2, min=epsilon))\n",
    "        edge2 = torch.sqrt(torch.clamp(edge2_x**2 + edge2_y**2, min=epsilon))\n",
    "        return F.smooth_l1_loss(edge1, edge2)\n",
    "\n",
    "    @staticmethod\n",
    "    def adaptive_generator_loss(real_preds, fake_preds):\n",
    "        rhl_loss = torch.mean(F.relu(1 - (fake_preds - torch.mean(real_preds))))\n",
    "        energy_loss = torch.mean(torch.exp(-fake_preds))\n",
    "        total_loss = rhl_loss + energy_loss + 1e-8\n",
    "        weight_rhl = rhl_loss / total_loss\n",
    "        weight_energy = energy_loss / total_loss\n",
    "        adaptive_loss = weight_rhl * rhl_loss + weight_energy * energy_loss\n",
    "        return adaptive_loss\n",
    "\n",
    "class TemporalGeneratorLoss(nn.Module):\n",
    "    def __init__(self, lambda_fooling=3.0, lambda_perceptual=1.5, lambda_ssim=1.8, lambda_edge=1.2, lambda_fa_em_gdl=2.3):\n",
    "        super().__init__()\n",
    "        #self.perceptual_loss = PerceptualLoss().cuda()\n",
    "        self.fa_em_gdl = FeatureAwareMultiScaleGDLoss(scales=3, lambda_edge=5.0, lambda_feature=1.0).cuda()\n",
    "        self.lambda_fooling = lambda_fooling\n",
    "        #self.lambda_perceptual = lambda_perceptual\n",
    "        #self.lambda_ssim = lambda_ssim\n",
    "        #self.lambda_edge = lambda_edge\n",
    "        self.lambda_fa_em_gdl = lambda_fa_em_gdl\n",
    "          \n",
    "    def forward(self, real_bg, reconstructed_bg, bg_discriminator_output, fake_bg_discriminator_output):\n",
    "         generator_fooling_loss = Utility.adaptive_generator_loss(bg_discriminator_output, fake_bg_discriminator_output)\n",
    "         loss_gdl = self.fa_em_gdl(reconstructed_bg, real_bg)\n",
    "         #perceptual_loss_val  = self.perceptual_loss(reconstructed_bg, real_bg) \n",
    "         #ssim_loss_val = (1 - Utility.ssim_windowed(real_bg, reconstructed_bg))\n",
    "         #edge_loss_val = Utility.edge_consistency(real_bg, reconstructed_bg)\n",
    "         total_loss = (self.lambda_fooling * generator_fooling_loss +\n",
    "                     # self.lambda_perceptual * perceptual_loss_val +\n",
    "                      #self.lambda_ssim * ssim_loss_val +\n",
    "                      #self.lambda_edge * edge_loss_val +\n",
    "                      self.lambda_fa_em_gdl * loss_gdl)\n",
    "\n",
    "         loss_dict = {\n",
    "             'adversarial_loss': generator_fooling_loss.detach(),\n",
    "             #'perceptual_loss': perceptual_loss_val.detach(),\n",
    "             #'ssim_loss': ssim_loss_val.detach(),\n",
    "             #'edge_loss': edge_loss_val.detach(),\n",
    "             'gdl_loss' : loss_gdl.detach()\n",
    "         }\n",
    "         return total_loss, loss_dict\n",
    "\n",
    "class SpatialGeneratorLoss(nn.Module):\n",
    "    def __init__(self, lambda_fooling=3.0, lambda_perceptual=1.3, lambda_ssim=2.4, lambda_edge=1.8, lambda_fa_em_gdl=2.3):\n",
    "        super().__init__()\n",
    "        #self.perceptual_loss = PerceptualLoss()\n",
    "        self.fa_em_gdl = FeatureAwareMultiScaleGDLoss(scales=3, lambda_edge=5.0, lambda_feature=1.0).cuda()\n",
    "        self.lambda_fooling = lambda_fooling\n",
    "        #self.lambda_perceptual = lambda_perceptual\n",
    "        #self.lambda_edge = lambda_edge\n",
    "        self.lambda_fa_em_gdl = lambda_fa_em_gdl\n",
    "        #self.lambda_ssim = lambda_ssim\n",
    "\n",
    "    def forward(self, real_fg, generated_fg, fg_discriminator_output, fake_fg_discriminator_output):\n",
    "        generator_fooling_loss = Utility.adaptive_generator_loss(fg_discriminator_output, fake_fg_discriminator_output)\n",
    "        loss_gdl = self.fa_em_gdl(generated_fg, real_fg)\n",
    "        #edge_loss_val = Utility.edge_consistency(real_fg, generated_fg)\n",
    "        #ssim_loss_val = 1 - Utility.ssim_windowed(real_fg, generated_fg)\n",
    "\n",
    "        total_loss = (self.lambda_fooling * generator_fooling_loss +\n",
    "                      #self.lambda_edge * edge_loss_val +\n",
    "                      #self.lambda_ssim * ssim_loss_val +\n",
    "                      self.lambda_fa_em_gdl * loss_gdl)\n",
    "\n",
    "        loss_dict = {\n",
    "            'adversarial_loss': generator_fooling_loss.detach(),\n",
    "            #'edge_loss': edge_loss_val.detach(),\n",
    "            #'ssim_loss': ssim_loss_val.detach(),\n",
    "            'gdl_loss' : loss_gdl.detach()\n",
    "        }\n",
    "        return total_loss, loss_dict\n",
    "\n",
    "class TemporalDiscriminatorLoss(nn.Module):\n",
    "    def __init__(self, lambda_hinge=1.2, lambda_adaptive_r1_penalty=10.0, lambda_multi_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.lambda_adaptive_r1_penalty = lambda_adaptive_r1_penalty\n",
    "        self.lambda_hinge = lambda_hinge\n",
    "        self.lambda_multi_scale = lambda_multi_scale\n",
    "        self.vgg = vgg19(pretrained=True).to(device).features[:8].eval()\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, Critic, real_bg_score, fake_bg_score, background_frame, fake_frame, step, generator_iters):\n",
    "        Hinge_loss = self.adaptive_combined_loss(real_bg_score, fake_bg_score)\n",
    "        multi_scale_loss_val = self._compute_multi_scale_penalty(background_frame, fake_frame, step, generator_iters)\n",
    "        adaptive_gp = self.compute_composite_penalty(Critic, background_frame, fake_frame, step, generator_iters)\n",
    "        total_loss = (self.lambda_hinge * Hinge_loss + self.lambda_multi_scale * multi_scale_loss_val + self.lambda_adaptive_r1_penalty * adaptive_gp)\n",
    "        loss_dict = {\n",
    "            'HingeLoss': Hinge_loss.detach(),\n",
    "            'gradient_penalty': adaptive_gp.detach(),\n",
    "            'multi_scale_loss': multi_scale_loss_val.detach()\n",
    "        }\n",
    "        return total_loss, loss_dict\n",
    "\n",
    "    def adaptive_combined_loss(self, real_preds, fake_preds):\n",
    "        rhl_real = torch.mean(F.relu(1 - (real_preds - torch.mean(fake_preds))))\n",
    "        rhl_fake = torch.mean(F.relu(1 + (fake_preds - torch.mean(real_preds))))\n",
    "        rhl_loss = rhl_real + rhl_fake\n",
    "        energy_real = torch.mean(torch.exp(-real_preds))\n",
    "        energy_fake = torch.mean(torch.exp(fake_preds))\n",
    "        energy_loss = energy_real + energy_fake\n",
    "        total_loss = rhl_loss + energy_loss + 1e-8\n",
    "        weight_rhl = rhl_loss / total_loss\n",
    "        weight_energy = energy_loss / total_loss\n",
    "        adaptive_loss = weight_rhl * rhl_loss + weight_energy * energy_loss\n",
    "        return adaptive_loss\n",
    "   \n",
    "    def _compute_multi_scale_penalty(self, real, fake, step, generator_iters):\n",
    "        real_features = self.vgg(real)\n",
    "        fake_features = self.vgg(fake)\n",
    "        lambda_f = self.lambda_multi_scale * max(0.1, (1 - (step / generator_iters)))\n",
    "        return lambda_f * F.mse_loss(real_features, fake_features)\n",
    "\n",
    "    def compute_composite_penalty(self, discriminator, real_images, fake_images, step, total_steps, lambda_R2=10.0, lambda_DRAGAN=10.0, lambda_LP=10.0, lambda_ctr=1.0, ctr_margin=1.0, device='cuda'):\n",
    "        progress_ratio = step / total_steps\n",
    "        adaptive_epsilon = self.lambda_adaptive_r1_penalty * max(0.1, 1.0 - progress_ratio)\n",
    "        real_images = real_images.to(device)\n",
    "        fake_images = fake_images.to(device)\n",
    "        # Composite penalty implementation (truncated for brevity)\n",
    "        return adaptive_epsilon * F.mse_loss(real_images, fake_images)  # Placeholder implementation\n",
    "class SpatialDiscriminatorLoss(nn.Module):\n",
    "    def __init__(self,lambda_hinge = 1.2,  lambda_adaptive_r1_penalty=10.0):\n",
    "        super().__init__()\n",
    "        self.lambda_adaptive_r1_penalty = lambda_adaptive_r1_penalty\n",
    "        self.lambda_hinge = lambda_hinge\n",
    "    \n",
    "    def forward(self,Critic, real_fg_score, fake_fg_score,foreground_frame,fake_frame,step,generator_iters):\n",
    "        # Hinge loss\n",
    "        hinge_loss_val = self.adaptive_combined_loss(real_fg_score,fake_fg_score,step,generator_iters) \n",
    "        \n",
    "        # Adaptive gradient penalty\n",
    "        adaptive_gp = self.compute_composite_penalty(\n",
    "           Critic, foreground_frame, fake_frame, step, generator_iters\n",
    "        )\n",
    "        total_loss = (hinge_loss_val  +  adaptive_gp)\n",
    "        loss_dict = {\n",
    "            'HingeLoss': hinge_loss_val.detach(),\n",
    "            'gradient_penalty': adaptive_gp.detach()\n",
    "        }\n",
    "        return total_loss, loss_dict\n",
    "    \n",
    "    def adaptive_combined_loss(self,real_preds, fake_preds, step,generator_iters):\n",
    "        \"\"\"\n",
    "        Adaptive hybrid loss combining Energy-Based GAN Loss and Relativistic Hinge Loss.\n",
    "        \n",
    "        Args:\n",
    "            real_preds: Discriminator outputs for real samples.\n",
    "            fake_preds: Discriminator outputs for fake samples.\n",
    "        \n",
    "        Returns:\n",
    "            Adaptive combined loss.\n",
    "        \"\"\"\n",
    "        # Relativistic Hinge Loss (RHL)\n",
    "        rhl_real = torch.mean(F.relu(1 - (real_preds - torch.mean(fake_preds))))\n",
    "        rhl_fake = torch.mean(F.relu(1 + (fake_preds - torch.mean(real_preds))))\n",
    "        rhl_loss = rhl_real + rhl_fake\n",
    "        \n",
    "        # Energy-Based GAN Loss\n",
    "        energy_real = torch.mean(torch.exp(-real_preds))\n",
    "        energy_fake = torch.mean(torch.exp(fake_preds))\n",
    "        energy_loss = energy_real + energy_fake\n",
    "        \n",
    "        # Compute Adaptive Weights\n",
    "        total_loss = rhl_loss + energy_loss + 1e-8  # Avoid division by zero\n",
    "        weight_rhl = rhl_loss / total_loss\n",
    "        weight_energy = energy_loss / total_loss\n",
    "\n",
    "        # Adaptive Combined Loss\n",
    "        adaptive_loss = weight_rhl * rhl_loss + weight_energy * energy_loss\n",
    "        lambda_hinge = self.lambda_hinge * max(0.1, (1 - (step / generator_iters)))  # Decay feature penalty\n",
    "        \n",
    "        return lambda_hinge * adaptive_loss\n",
    "   \n",
    "    \n",
    "    def _compute_edge_frequency_penalty(self, real, fake, step,generator_iters):\n",
    "        \"\"\"\n",
    "        Compute Multi-Scale Feature Consistency Loss\n",
    "        \n",
    "        :param real: Real images\n",
    "        :param fake: Fake images\n",
    "        :param step: Current training step\n",
    "        :return: Feature loss (reducing over time)\n",
    "        \"\"\"\n",
    "        real_fft = torch.fft.fft2(real)\n",
    "        fake_fft = torch.fft.fft2(fake)\n",
    "        \n",
    "        freq_diff = torch.abs(real_fft - fake_fft)\n",
    "        lambda_f = self.lambda_edge_frequency * max(0.1, (1 - (step / generator_iters)))  # Decay feature penalty\n",
    "        \n",
    "        return lambda_f * torch.mean(freq_diff)  # Penalize high-frequency loss\n",
    "    def compute_composite_penalty(self,discriminator, real_images, fake_images,  step, total_steps,\n",
    "                              lambda_R2=10.0, lambda_DRAGAN=10.0, lambda_LP=10.0, \n",
    "                              lambda_ctr=1.0, ctr_margin=1.0, device='cuda'):\n",
    "        \"\"\"\n",
    "        Compute a composite penalty loss from several components:\n",
    "        1. Zero-Centered (R2) Gradient Penalty (on both real and fake samples)\n",
    "        2. DRAGAN Penalty (on perturbed real samples)\n",
    "        3. WGAN-LP style penalty (on interpolated samples)\n",
    "        4. Contrastive Penalty (using features from discriminator)\n",
    "        \n",
    "        Assumes that the discriminator returns both a scalar output and an intermediate\n",
    "        feature representation when called as:\n",
    "            score, features = discriminator(x)\n",
    "        \n",
    "        Parameters:\n",
    "        discriminator : callable\n",
    "            The discriminator network (with spectral normalization already applied).\n",
    "        real_images : torch.Tensor\n",
    "            Batch of real images.\n",
    "        fake_images : torch.Tensor\n",
    "            Batch of generated (fake) images.\n",
    "        lambda_R2 : float\n",
    "            Weight for the Zero-Centered (R2) gradient penalty.\n",
    "        lambda_DRAGAN : float\n",
    "            Weight for the DRAGAN penalty.\n",
    "        lambda_LP : float\n",
    "            Weight for the WGAN-LP penalty.\n",
    "        lambda_ctr : float\n",
    "            Weight for the contrastive penalty.\n",
    "        ctr_margin : float\n",
    "            Margin used in the contrastive loss.\n",
    "        device : str\n",
    "            Device to perform computations on.\n",
    "        \n",
    "        Returns:\n",
    "        total_penalty : torch.Tensor\n",
    "            The weighted sum of all penalty components.\n",
    "        penalty_dict : dict\n",
    "            Dictionary with individual penalty terms (for logging/debugging).\n",
    "        \"\"\"\n",
    "        # Adaptive gradient penalty based on training progression\n",
    "        progress_ratio = step / total_steps\n",
    "        adaptive_epsilon =self.lambda_adaptive_r1_penalty *  max(0.1, 1.0 - progress_ratio)\n",
    "        # Ensure images require gradients for penalty computations\n",
    "        real_images = real_images.to(device)\n",
    "        fake_images = fake_images.to(device)\n",
    "\n",
    "        # ===============================\n",
    "        # 1. Zero-Centered (R2) Gradient Penalty\n",
    "        # Compute gradients of discriminator output w.r.t. input for both real and fake images.\n",
    "        def gradient_penalty(x):\n",
    "            # Compute discriminator output (scalar score)\n",
    "            score = discriminator(x)\n",
    "            grad_out = grad(outputs=score.sum(), inputs=x,\n",
    "                            create_graph=True, retain_graph=True)[0]\n",
    "            grad_norm = grad_out.view(grad_out.size(0), -1).norm(2, dim=1)\n",
    "            return grad_norm\n",
    "\n",
    "        grad_norm_real = gradient_penalty(real_images)\n",
    "        grad_norm_fake = gradient_penalty(fake_images)\n",
    "        # R2 penalty: encourage gradients to be close to zero (or small)\n",
    "        penalty_R2 = torch.mean(grad_norm_real**2 + grad_norm_fake**2)\n",
    "\n",
    "        # ===============================\n",
    "        # 2. DRAGAN Penalty\n",
    "        # Perturb real images with small noise and penalize the gradient norm.\n",
    "        alpha = torch.rand(real_images.size(0), 1, 1, 1, device=device)\n",
    "        # Noise standard deviation is proportional to the std of the real images.\n",
    "        noise = 0.5 * real_images.std() * torch.randn_like(real_images)\n",
    "        perturbed_real = real_images + alpha * noise\n",
    "        score_perturb = discriminator(perturbed_real)\n",
    "        grad_perturb = grad(outputs=score_perturb.sum(), inputs=perturbed_real,\n",
    "                            create_graph=True, retain_graph=True)[0]\n",
    "        grad_norm_perturb = grad_perturb.view(grad_perturb.size(0), -1).norm(2, dim=1)\n",
    "        penalty_DRAGAN = torch.mean((grad_norm_perturb - 1.0)**2)\n",
    "\n",
    "        # ===============================\n",
    "        # 3. WGAN-LP style penalty\n",
    "        # Interpolate between real and fake samples and penalize only when gradient norm > 1.\n",
    "        beta = torch.rand(real_images.size(0), 1, 1, 1, device=device)\n",
    "        interpolates = beta * real_images + (1 - beta) * fake_images\n",
    "        score_interp = discriminator(interpolates)\n",
    "        grad_interp = grad(outputs=score_interp.sum(), inputs=interpolates,\n",
    "                        create_graph=True, retain_graph=True)[0]\n",
    "        grad_norm_interp = grad_interp.view(grad_interp.size(0), -1).norm(2, dim=1)\n",
    "        penalty_LP = torch.mean(torch.clamp(grad_norm_interp - 1, min=0) ** 2)\n",
    "\n",
    "        # ===============================\n",
    "        # 4. Contrastive Penalty\n",
    "        # Use feature representations from the discriminator to enforce that real and fake images\n",
    "        # are separated in feature space. Here, we assume that real images should have similar features,\n",
    "        # while fake images should lie outside a margin.\n",
    "        # For simplicity, compute distances between each real and corresponding fake feature.\n",
    "        feat_real = discriminator(real_images)\n",
    "        feat_fake = discriminator(fake_images)\n",
    "        # Compute L2 distance between feature pairs (assume batches are aligned)\n",
    "        feat_distance = F.pairwise_distance(feat_real, feat_fake, p=2)\n",
    "        # For contrastive loss, if the distance is less than the margin, incur a loss.\n",
    "        contrastive_loss = torch.mean(torch.clamp(ctr_margin - feat_distance, min=0) ** 2)\n",
    "\n",
    "         \n",
    "        total_penalty = adaptive_epsilon  * (lambda_R2 * penalty_R2) +(lambda_DRAGAN * penalty_DRAGAN) +(lambda_LP * penalty_LP)+(lambda_ctr * contrastive_loss)\n",
    "        \n",
    "        return total_penalty\n",
    "\n",
    "    def _compute_adaptive_r1_penalty(self, real_data, \n",
    "                                           real_preds, step, total_steps):\n",
    "        # Adaptive gradient penalty based on training progression\n",
    "        progress_ratio = step / total_steps\n",
    "        adaptive_epsilon =self.lambda_adaptive_r1_penalty *  max(0.1, 1.0 - progress_ratio)\n",
    "        grad_outputs = torch.ones_like(real_preds, requires_grad=False)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=real_preds, inputs=real_data,\n",
    "            grad_outputs=grad_outputs, create_graph=True, retain_graph=True, only_inputs=True\n",
    "        )[0]\n",
    "\n",
    "        return adaptive_epsilon  * torch.mean(gradients.norm(2, dim=1) ** 2)\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, layers=[\"conv5_1\", \"conv5_2\"]):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        vgg = vgg19(pretrained=True).to(device).features.eval()  # Pre-trained VGG19\n",
    "        self.selected_layers = layers\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.model = nn.Sequential(*list(vgg.children()))\n",
    "        self.model.requires_grad_(False)\n",
    "        self.loss_fn = nn.MSELoss()  # You can also use L1Loss\n",
    "    def get_features(self, input):\n",
    "        return self.model(self.normalize(input))\n",
    "    def forward(self, input, target):\n",
    "        sep = input.shape[0]\n",
    "        batch = torch.cat([input, target])\n",
    "        feats = self.get_features(batch)\n",
    "        input_feats, target_feats = feats[:sep], feats[sep:]\n",
    "        return F.mse_loss(input_feats, target_feats, reduction='mean')\n",
    "\n",
    "class FeatureAwareMultiScaleGDLoss(nn.Module):\n",
    "    def __init__(self, scales=3, lambda_edge=5.0, lambda_feature=1.0):\n",
    "        \"\"\"\n",
    "        Feature-Aware Edge-Aware Multi-Scale Gradient Difference Loss (FA-EM-GDL)\n",
    "        :param scales: Number of multi-scale levels\n",
    "        :param lambda_edge: Weight for edge importance\n",
    "        :param lambda_feature: Weight for feature-based GDL\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.scales = scales\n",
    "        self.lambda_edge = lambda_edge\n",
    "        self.lambda_feature = lambda_feature\n",
    "\n",
    "        # Sobel filters for edge detection\n",
    "        self.sobel_x = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.sobel_y = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        sobel_kernel_x = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
    "        sobel_kernel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.sobel_x.weight.copy_(sobel_kernel_x)\n",
    "            self.sobel_y.weight.copy_(sobel_kernel_y)\n",
    "\n",
    "        # Load a pretrained VGG model for feature extraction\n",
    "        \n",
    "        vgg = vgg19(pretrained=True).features\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg.children())[:8])  # Extracting early layers\n",
    "\n",
    "        # Freeze VGG layers\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def compute_gradient(self, img):\n",
    "        \"\"\" Compute image gradients using Sobel filter \"\"\"\n",
    "        if img.shape[1] == 3:  # Convert RGB to grayscale\n",
    "            img = torch.mean(img, dim=1, keepdim=True)\n",
    "        grad_x = self.sobel_x(img)\n",
    "        grad_y = self.sobel_y(img)\n",
    "        return grad_x, grad_y\n",
    "\n",
    "    def compute_edge_weight(self, img):\n",
    "        \"\"\" Compute edge-aware weight map using Sobel edge detection \"\"\"\n",
    "        if img.shape[1] == 3:  # Convert RGB to grayscale\n",
    "            img = torch.mean(img, dim=1, keepdim=True)\n",
    "        edge_x = self.sobel_x(img)\n",
    "        edge_y = self.sobel_y(img)\n",
    "        \n",
    "        eps = 1e-6  # Small value to prevent sqrt(0) or NaN issues\n",
    "        edge_magnitude = torch.sqrt(edge_x ** 2 + edge_y ** 2 + eps)\n",
    "        \n",
    "        return 1 + self.lambda_edge * edge_magnitude\n",
    "\n",
    "    def forward(self, gen_frames, gt_frames):\n",
    "        \"\"\"\n",
    "        Compute Feature-Aware Edge-aware Multi-Scale Gradient Difference Loss\n",
    "        :param gen_frames: Generated frames (Bx1xHxW)\n",
    "        :param gt_frames: Ground truth frames (Bx1xHxW)\n",
    "        :return: FA-EM-GDL loss\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        weight_sum = 0.0\n",
    "        for s in range(self.scales):\n",
    "            # Compute gradients\n",
    "            gen_grad_x, gen_grad_y = self.compute_gradient(gen_frames)\n",
    "            gt_grad_x, gt_grad_y = self.compute_gradient(gt_frames)\n",
    "            \n",
    "            # Compute edge-aware weight\n",
    "            edge_weight = self.compute_edge_weight(gt_frames)\n",
    "\n",
    "            # Compute edge-aware GDL at this scale\n",
    "            \n",
    "            scale_loss = torch.mean(edge_weight * (torch.abs(gen_grad_x - gt_grad_x) + torch.abs(gen_grad_y - gt_grad_y)))\n",
    "            if gen_frames.shape[1] == 1:  # Convert grayscale to 3 channels\n",
    "                gen_frames = gen_frames.expand(-1, 3, -1, -1)\n",
    "                gt_frames = gt_frames.expand(-1, 3, -1, -1)\n",
    "            # Compute feature-aware loss\n",
    "            gen_features = self.feature_extractor(gen_frames)  \n",
    "            gt_features = self.feature_extractor(gt_frames)\n",
    "            feature_loss = torch.mean(torch.abs(gen_features - gt_features))\n",
    "\n",
    "            # Scale weight (higher for finer scales)\n",
    "            alpha_s = 1.0 / (2 ** s)\n",
    "            loss += alpha_s * (scale_loss + self.lambda_feature * feature_loss)\n",
    "            weight_sum += alpha_s\n",
    "\n",
    "            # Downscale for multi-scale effect\n",
    "            if s < self.scales - 1:\n",
    "                gen_frames = F.avg_pool2d(gen_frames, kernel_size=2, stride=2)\n",
    "                gt_frames = F.avg_pool2d(gt_frames, kernel_size=2, stride=2)\n",
    "\n",
    "        return loss / weight_sum  # Normalize loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Train Module Overview\n",
    "This module orchestrates the complete training pipeline for the STARGA model used in video anomaly detection. It is responsible for dataset loading, model initialization, training loop management, and periodic evaluation & checkpointing. The module leverages various PyTorch utilities and custom components to ensure robust and efficient training.\n",
    "\n",
    "## ðŸ“¦ Data Loading & Preprocessing\n",
    "### Dataset Integration:\n",
    "The module imports the dataset module to load video data and creates a PyTorch DataLoader to iterate through training sequences. It also applies data augmentations such as color jittering, translation, cutout, and adaptive noise via the diff_augment function.\n",
    "\n",
    "### Transformations & Utilities:\n",
    "Several image transformation utilities (from PIL and torchvision) are used to ensure images are correctly resized, normalized, and formatted for training.\n",
    "\n",
    "## âš™ï¸ Model Initialization & Optimizers\n",
    "### Model Components:\n",
    "The training script initializes four core components:\n",
    "\n",
    "### Temporal Generator & Critic: Handle frame differencing and temporal dynamics.\n",
    "\n",
    "### Spatial Generator & Critic: Focus on generating and assessing spatial features.\n",
    "\n",
    "## Loss Functions:\n",
    "Custom loss functions (temporal & spatial generator/discriminator losses) guide the network training, combining adversarial, perceptual, SSIM, edge consistency, and gradient-based penalties.\n",
    "\n",
    "## Optimizers & Schedulers:\n",
    "AdamW optimizers are configured for each network, with learning rate schedulers (Cosine Annealing Warm Restarts) to smoothly adjust learning rates during training. Optionally, pretrained model weights can be resumed.\n",
    "\n",
    "## ðŸ”„ Training Loop & Updates\n",
    "### Training Process:\n",
    "The main training loop runs until the specified generator iterations are reached. For each batch:\n",
    "\n",
    "### Discriminator Steps:\n",
    "The critics are updated using augmented inputs. The script computes temporal and spatial losses and performs gradient updates.\n",
    "\n",
    "### Generator Steps:\n",
    "The generators are updated subsequently. EMA (Exponential Moving Average) is used to stabilize the generator training.\n",
    "\n",
    "### Gradient Clipping & Scheduler Steps:\n",
    "To prevent exploding gradients, gradient clipping is applied. Learning rate schedulers are updated at the end of each epoch.\n",
    "\n",
    "### Logging & Checkpointing:\n",
    "Training metrics (losses, learning rates, FID scores, etc.) are logged using TensorBoard and saved periodically to disk. The best model is tracked and updated based on evaluation performance.\n",
    "\n",
    "## ðŸ› ï¸ Evaluation & Checkpointing\n",
    "### Validation:\n",
    "The training script includes a validation routine that periodically computes metrics (e.g., AUC, FID) on the training and testing data.\n",
    "\n",
    "### Model Saving:\n",
    "The script saves model checkpoints at defined intervals and updates the best model when improved performance is observed.\n",
    "\n",
    "### Inception Model for FID:\n",
    "A pretrained Inception-v3 model is used to extract features and compute the FrÃ©chet Inception Distance (FID), which serves as a quality metric for the generated frames.\n",
    "\n",
    "## âš¡ Command-Line Interface\n",
    "### Argument Parsing:\n",
    "The script uses argparse to allow flexible configuration of hyperparameters such as batch size, dataset name, learning rates, resume paths, and iteration counts. This makes the module easily adaptable for different environments, whether running locally or on Kaggle.\n",
    "\n",
    "### Configuration Updates:\n",
    "The parsed arguments are passed to the configuration module, which sets up the environment accordingly (e.g., determining file paths, enabling CUDA, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.215697Z",
     "iopub.status.busy": "2025-04-19T06:01:06.215419Z",
     "iopub.status.idle": "2025-04-19T06:01:06.226531Z",
     "shell.execute_reply": "2025-04-19T06:01:06.225335Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.215675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import torch \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from scipy.linalg import sqrtm\n",
    "import dataset\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, ToPILImage, Grayscale\n",
    "import torchvision.transforms as transforms\n",
    "from loss import TemporalGeneratorLoss,TemporalDiscriminatorLoss,SpatialGeneratorLoss,SpatialDiscriminatorLoss\n",
    "from model import *\n",
    "from save_func import * \n",
    "from test_eval import *\n",
    "import time\n",
    "import datetime\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "from config import update_config\n",
    "from utils import *\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.clone().detach() for k, v in model.state_dict().items()}\n",
    "    def update(self):\n",
    "        for k, v in self.model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_((1 - self.decay) * v)\n",
    "    def apply_shadow(self):\n",
    "        self.model.load_state_dict(self.shadow)\n",
    "class STARGA(object): \n",
    "    def __init__(self, args):\n",
    "        print(\"WGAN_Stage init model.\")\n",
    "        # self.flow_loss = Flow_Loss().cuda()\n",
    "        self.img_shape = (3, 256, 256)\n",
    "        self.flow_shape = (2, 256, 256)\n",
    "        self.latent_dim = 16\n",
    "        self.num_frames = 10  # Number of frames per video\n",
    "    \n",
    "        self.TemporalGenerator = TemporalGenerator().to(device) # Frame Differencing Change detection\n",
    "        self.TemporalCritic = TemporalCritic().to(device) # Frame Differencing Change detection\n",
    "        self.SpatialGenerator = SpatialGenerator().to(device) \n",
    "        self.SpatialCritic = SpatialCritic().to(device)  \n",
    "        self.temporal_generator_loss = TemporalGeneratorLoss(lambda_fooling= 2.5, lambda_perceptual=3.2, lambda_ssim=3.4, lambda_edge=3.3,lambda_fa_em_gdl=2.2)\n",
    "        self.temporal_critic_loss = TemporalDiscriminatorLoss(lambda_hinge = 1.2, lambda_adaptive_r1_penalty = 10.0, lambda_multi_scale=2.0)\n",
    "        self.spatial_generator_loss = SpatialGeneratorLoss(lambda_fooling = 2.5, lambda_ssim=3.4, lambda_edge=3.3,lambda_fa_em_gdl=2.2)\n",
    "        self.spatial_critic_loss = SpatialDiscriminatorLoss(lambda_hinge = 1.2,  lambda_adaptive_r1_penalty=10.0)\n",
    "        \n",
    "        self.g_loss_temporal_separate_list={  \n",
    "            # \n",
    "              'adversarial_loss' : [],\n",
    "             #'perceptual_loss' : [],\n",
    "            # 'ssim_loss' : [],\n",
    "            # 'edge_loss' : [],\n",
    "             'gdl_loss' :[]\n",
    "             }\n",
    "     \n",
    "        self.d_loss_temporal_separate_list= {'HingeLoss' : [],\n",
    "                'gradient_penalty' : [],\n",
    "                   'multi_scale_loss': [],\n",
    "            # 'div_penalty': []\n",
    "             }\n",
    "        self.g_loss_spatial_separate_list={'adversarial_loss' : [],\n",
    "            #   'perceptual_loss' : [],\n",
    "            #'edge_loss': [],\n",
    "            # 'ssim_loss': [],\n",
    "             'gdl_loss' :[]\n",
    "             }\n",
    "        \n",
    "        self.d_loss_spatial_separate_list=  {'HingeLoss' : [],\n",
    "                'gradient_penalty' :  []\n",
    "             }\n",
    "        # Check if cuda is available\n",
    "        self.check_cuda(args.cuda)\n",
    "\n",
    "        # WGAN values from paper The Two Time-Scale Update Rule (TTUR) helps balance the learning rates of the generator and critic to ensure stable GAN training. TTUR suggests using different learning rates for the generator and the critic.\n",
    "        if args.resume:\n",
    "            if args.is_local:\n",
    "                model_path = 'D:\\\\'+args.resume+'.pth'\n",
    "            else:\n",
    "                model_path = '/kaggle/working/weights/'+args.resume+'.pth'\n",
    "            model = torch.load(model_path, weights_only=False)\n",
    "            self.learning_rate_temporal_generator =  model['learning_rate_delta_generator']\n",
    "            self.learning_rate_temporal_critic = model['learning_rate_delta_critic']\n",
    "            self.learning_rate_spatial_generator = model['learning_rate_Flux_generator']\n",
    "            self.learning_rate_spatial_critic = model['learning_rate_Flux_critic']\n",
    "           \n",
    "        else:\n",
    "            self.learning_rate_temporal_generator = 4.0e-4  \n",
    "            self.learning_rate_temporal_critic = 5.0e-05 \n",
    "            self.learning_rate_spatial_generator = 8.0e-4\n",
    "            self.learning_rate_spatial_critic = 5.0e-5 \n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.batch_size = args.batch_size\n",
    "        self.dg_optimizer = torch.optim.AdamW(self.TemporalGenerator.parameters(), lr=self.learning_rate_temporal_generator, betas=(self.b1, self.b2), weight_decay=1e-5)\n",
    "        self.dc_optimizer = torch.optim.AdamW(self.TemporalCritic.parameters(), lr=self.learning_rate_temporal_critic, betas=(self.b1, self.b2), weight_decay=1e-5)\n",
    "        self.fg_optimizer = torch.optim.AdamW(self.SpatialGenerator.parameters(), lr=self.learning_rate_spatial_generator, betas=(self.b1, self.b2), weight_decay=1e-5)\n",
    "        self.fc_optimizer = torch.optim.AdamW(self.SpatialCritic.parameters(), lr=self.learning_rate_spatial_critic, betas=(self.b1, self.b2), weight_decay=1e-5)\n",
    "\n",
    "        # Add learning rate scheduler\n",
    "        self.dg_cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.dg_optimizer, T_0=25, T_mult=2, eta_min=5e-7)\n",
    "        self.dc_cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.dc_optimizer, T_0=25, T_mult=2, eta_min=5e-7)\n",
    "        self.fg_cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.fg_optimizer, T_0=25, T_mult=2, eta_min=5e-7)\n",
    "        self.fc_cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.fc_optimizer, T_0=25, T_mult=2, eta_min=5e-7)\n",
    "       \n",
    "        self.generator_iters = args.generator_iters\n",
    "        self.critic_iter = 1\n",
    "        self.generator_iter = 1\n",
    "        self.load_models(args)\n",
    "        \n",
    "    def step_all_schedulers(self,schedulers):\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "   \n",
    "   \n",
    "    def check_cuda(self, cuda_flag=False):\n",
    "        print(cuda_flag)\n",
    "        if cuda_flag:\n",
    "            self.cuda_index = 0\n",
    "            self.cuda = True\n",
    "            self.TemporalCritic.cuda(self.cuda_index)\n",
    "            self.TemporalGenerator.cuda(self.cuda_index)\n",
    "            self.SpatialGenerator.cuda(self.cuda_index)\n",
    "            self.SpatialCritic.cuda(self.cuda_index)\n",
    "            print(\"Cuda enabled flag: {}\".format(self.cuda))\n",
    "        else:\n",
    "            self.cuda = False\n",
    "    def get_torch_variable(self,  arg):\n",
    "        if cuda:\n",
    "            return Variable(arg, requires_grad=True).to(device)\n",
    "        else:\n",
    "            return Variable(arg, requires_grad=True)\n",
    " \n",
    "    def load_models(self,cfg):\n",
    "        if cfg.resume:\n",
    "            if cfg.is_local:\n",
    "                model_path = 'D:\\\\'+cfg.resume+'.pth'\n",
    "            else:\n",
    "                model_path = '/kaggle/working/weights/'+cfg.resume+'.pth'\n",
    "            model = torch.load(model_path, weights_only=False)\n",
    "            self.TemporalCritic.load_state_dict(model['net_dc'])\n",
    "            self.SpatialCritic.load_state_dict(model['net_fc'])\n",
    "            self.TemporalGenerator.load_state_dict(model['net_dg'])\n",
    "            self.SpatialGenerator.load_state_dict(model['net_fg'])\n",
    "            self.dg_optimizer.load_state_dict(model['optimizer_dg'])\n",
    "            self.dc_optimizer.load_state_dict(model['optimizer_dc'])\n",
    "            self.fg_optimizer.load_state_dict(model['optimizer_fg'])\n",
    "            self.fc_optimizer.load_state_dict(model['optimizer_fc'])\n",
    "        else:\n",
    "            self.TemporalGenerator.apply(weights_init_normal)\n",
    "            self.TemporalCritic.apply(weights_init_normal)\n",
    "            self.SpatialGenerator.apply(weights_init_normal)\n",
    "            self.SpatialCritic.apply(weights_init_normal)\n",
    "\n",
    "    # Check if tensors require gradients before the penalty calculation\n",
    "    def check_requires_grad(self,tensor, tensor_name):\n",
    "        if not tensor.requires_grad:\n",
    "            print(f\"Warning: {tensor_name} does not require gradients.\")\n",
    "        else:\n",
    "            print(f\"{tensor_name} requires gradients.\")\n",
    "   \n",
    "    def val(self,cfg,IsModels=False, train_scores=None, iter=None):\n",
    "        '''\n",
    "        ========================================\n",
    "        This is for evaluation during training.    \n",
    "        ========================================\n",
    "        '''\n",
    "        if IsModels:  \n",
    "            self.TemporalGenerator.eval()\n",
    "            self.TemporalCritic.eval()\n",
    "            self.SpatialGenerator.eval()\n",
    "            self.SpatialCritic.eval()\n",
    "\n",
    "            # validation \n",
    "            dauc,mauc,fauc, train_scores = val_train_eval(self,cfg, train_scores, iter)\n",
    "\n",
    "            return dauc,mauc,fauc, train_scores\n",
    "\n",
    "        '''\n",
    "        ========================================\n",
    "        This is for evaluation during testing.    \n",
    "        ========================================\n",
    "        '''\n",
    "        \n",
    "        if cfg.trained_model:\n",
    "            if cfg.is_local:\n",
    "                model_path = 'D:\\\\'+cfg.trained_model+'.pth'\n",
    "            else:\n",
    "                model_path = '/kaggle/working/weights/'+cfg.trained_model+'.pth'\n",
    "            model = torch.load(model_path, weights_only=False)\n",
    "            self.TemporalGenerator.load_state_dict(model['net_dg'])\n",
    "            self.SpatialGenerator.load_state_dict(model['net_fg'])\n",
    "            self.TemporalCritic.load_state_dict(model['net_dc'])\n",
    "            self.SpatialCritic.load_state_dict(model['net_fc'])\n",
    "            iter = model['step']\n",
    "            self.TemporalGenerator.eval()\n",
    "            self.SpatialGenerator.eval()\n",
    "            self.TemporalCritic.eval()\n",
    "            self.SpatialCritic.eval()\n",
    "\n",
    "            val_test_eval(cfg, self, iter)\n",
    "        else:\n",
    "            print('no trained model!')\n",
    "   \n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Rare Event Detection')\n",
    "    parser.add_argument('--batch_size', default=3, type=int)\n",
    "    parser.add_argument('--dataset', default='ped2', type=str, choices=['ped2', 'ped1', 'avenue'], help='The name of the dataset to train.')\n",
    "    parser.add_argument('--resume', default='latest_ped2', type=str, help='The pre-trained model to resume training with.')\n",
    "    parser.add_argument('--save_interval', default=1, type=int, help='Save the model every [save_interval] iterations.')\n",
    "    parser.add_argument('--val_interval', default=30, type=int, help='Evaluate the model every [val_interval] iterations.')\n",
    "    parser.add_argument('--manualseed', default=-1, type=int, help='manual seed')\n",
    "    parser.add_argument('--generator_iters', type=int, default=20000, help='The number of iterations for generator in WGAN model.')\n",
    "    parser.add_argument('--cuda', type=str, default='True', help='Availability of cuda')\n",
    "    parser.add_argument('--show_flow', default=False, action='store_true', help='If True, visualize optic flow.')\n",
    "    parser.add_argument('--is_local', default=False, action='store_true', help='If True, use local path else gdrive path.')\n",
    "    args = parser.parse_args()\n",
    "    train_cfg = update_config(args, mode='train')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    print(device)\n",
    "    seed(seed_value=train_cfg.manualseed)\n",
    "    train_dataset_obj = dataset.train_dataset(train_cfg, transform=None)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset_obj, batch_size=train_cfg.batch_size, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "    print_infor(cfg=train_cfg, dataloader=train_dataloader)\n",
    "    STARGA(train_cfg).training(train_cfg, train_dataset_obj, train_dataloader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§ª Evaluation Script Overview\n",
    "This script sets up and runs the evaluation phase of the ST-GAN model on a specified dataset. It uses command-line arguments to configure the evaluation environment, loads the trained model, and then performs model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.229388Z",
     "iopub.status.busy": "2025-04-19T06:01:06.229100Z",
     "iopub.status.idle": "2025-04-19T06:01:06.253905Z",
     "shell.execute_reply": "2025-04-19T06:01:06.252819Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.229361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile eval.py\n",
    "\n",
    "from config import update_config\n",
    "from train import STARGA\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='ST-GAN')\n",
    "parser.add_argument('--dataset', default='ped2', type=str, help='The name of the dataset to evaluate.')\n",
    "parser.add_argument('--trained_model', default='latest_ped2', type=str, help='The pre-trained model to evaluate. best_model_ped2 OR latest_ped2')\n",
    "parser.add_argument('--show_curve', default=True, type=bool, help='show curve')\n",
    "parser.add_argument('--show_heatmap', default=True, type=bool, help='show heatmap')\n",
    "parser.add_argument('--generator_iters', type=int, default=20000, help='The number of iterations for generator in WGAN model.')\n",
    "parser.add_argument('--cuda',  type=str, default='True', help='Availability of cuda')\n",
    "parser.add_argument('--batch_size', default=1, type=int)\n",
    "parser.add_argument('--manualseed', default=-1, type=int, help='manual seed')\n",
    "parser.add_argument('--resume', default=None, type=str,\n",
    "                        help='The pre-trained model to resume training with, pass \\'latest\\' or the model name.')\n",
    "parser.add_argument('--is_local', default=False, action='store_true',\n",
    "                    help='If True, local path else gdrive path.')\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    test_cfg = update_config(args, mode='test')\n",
    "    test_cfg.print_cfg()\n",
    "    # setup seed (for deterministic behavior)\n",
    "    seed(seed_value=test_cfg.manualseed)\n",
    "    STARGA(test_cfg).val(test_cfg,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” Test & Evaluation Module Overview\n",
    "This module performs evaluation of the video anomaly detection model on testing data. It loads test video sequences, computes anomaly scores by comparing generated outputs with ground truth frames, and ultimately aggregates these scores to calculate metrics such as PSNR and ROC-AUC.\n",
    "\n",
    "## ðŸ”¢ Utility Functions\n",
    "### min_max_normalize:\n",
    "Normalizes an input NumPy array to the range [0, 1] by using the minimum and maximum values. A small epsilon is added to avoid division by zero.\n",
    "\n",
    "### psnr_park:\n",
    "Computes the Peak Signal-to-Noise Ratio (PSNR) from the mean squared error (MSE). This is a measure of image quality, where higher values indicate better quality.\n",
    "\n",
    "## ðŸ§ª Evaluation Process\n",
    "The primary function in this module is val_test_eval, which performs the following tasks:\n",
    "\n",
    "### Data Loading:\n",
    "\n",
    "Retrieves the list of video folders from the testing directory.\n",
    "\n",
    "Instantiates the custom test dataset and dataloader to iterate over video sequences.\n",
    "\n",
    "Loads ground truth labels using the Label_loader class.\n",
    "\n",
    "### Score Calculation:\n",
    "For each video clip:\n",
    "\n",
    "Iterates through each frame in the clip.\n",
    "\n",
    "Passes the frames through the Temporal and Spatial Generators to generate corresponding fake frames.\n",
    "\n",
    "Computes PSNR-based errors between generated and real frames to obtain temporal, spatial, and combined anomaly scores.\n",
    "\n",
    "Aggregates these scores along with the ground truth for later evaluation.\n",
    "\n",
    "### Metrics Aggregation:\n",
    "Uses a custom meter (here, Meter_AnoGAN) to update and collect anomaly scores for the entire test set, which can later be used to calculate metrics like ROC-AUC.\n",
    "\n",
    "### Optional Heatmap Visualization:\n",
    "Provides a placeholder to save heatmaps and images for further qualitative analysis if the configuration enables it.\n",
    "\n",
    "## âš™ï¸ Integration with the Model\n",
    "The evaluation function receives the current configuration (cfg) and a reference to the trained model (self). It calls the generators to produce fake temporal and spatial frames, which are then compared to the corresponding ground truth using PSNR-based error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.255769Z",
     "iopub.status.busy": "2025-04-19T06:01:06.255454Z",
     "iopub.status.idle": "2025-04-19T06:01:06.269663Z",
     "shell.execute_reply": "2025-04-19T06:01:06.268855Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.255739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_eval.py\n",
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataset import Label_loader\n",
    "import dataset\n",
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from utils import *\n",
    "\n",
    "def min_max_normalize(arr, eps=1e-8):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    denominator = max_val - min_val + eps\n",
    "    normalized_arr = (arr - min_val) / denominator   \n",
    "    return normalized_arr\n",
    "\n",
    "def psnr_park(mse):\n",
    "    return 10 * math.log10(1 / mse)\n",
    "\n",
    "def val_test_eval(cfg, self, iter):\n",
    "    dataset_name = cfg.dataset\n",
    "    video_folders = os.listdir(cfg.test_data)\n",
    "    video_folders.sort()\n",
    "    video_folders = [os.path.join(cfg.test_data, aa) for aa in video_folders]\n",
    "    abnormaltest_dataset = dataset.test_dataset(cfg)\n",
    "    abnormaltest_dataloader = DataLoader(dataset=abnormaltest_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    meter = Meter_AnoGAN()\n",
    "    psnrs = []\n",
    "    psnr_group = []\n",
    "    auc = 0\n",
    "    fake_scores = []\n",
    "    real_scores = []\n",
    "    y_true = []\n",
    "    gt_loader = Label_loader(cfg, video_folders)\n",
    "    gt = gt_loader()\n",
    "    video_num = 0\n",
    "    sabnormal_score = []\n",
    "    tabnormal_score = []\n",
    "    cabnormal_score = []\n",
    "    ground_truths = []\n",
    "    combine_scores = []\n",
    "    with torch.no_grad():\n",
    "        for _, [clips, diff_frames, edge_frames, background_image, video_id, num_frames] in enumerate(abnormaltest_dataloader):\n",
    "            if video_id != video_num:\n",
    "                video_num = video_id\n",
    "                sabnormal_score = []\n",
    "                tabnormal_score = []\n",
    "                cabnormal_score = []\n",
    "                ground_truths = [] \n",
    "                combine_scores = []\n",
    "            real_video = clips.to(device)\n",
    "            for j in range(len(clips[0])):\n",
    "                real_frame = real_video[:, j, :, :, :]\n",
    "                diff_frame = diff_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                edge_frame = edge_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                background_image = background_image.to(device)\n",
    "                fake_temporal_frame = self.TemporalGenerator(background_image, real_frame, iter, cfg.generator_iters).detach()\n",
    "                fake_spatial_frame = self.SpatialGenerator(real_frame, iter, cfg.generator_iters).detach()\n",
    "                stest_loss = float(psnr_error(fake_spatial_frame, edge_frame).cpu().detach().numpy())\n",
    "                ttest_loss = float(psnr_error(fake_temporal_frame, diff_frame).cpu().detach().numpy())\n",
    "                combine_scores.append(stest_loss + ttest_loss)\n",
    "                cresidual_loss = float(psnr_error(fake_spatial_frame + fake_temporal_frame, diff_frame + edge_frame).cpu().detach().numpy())\n",
    "                sabnormal_score.append(stest_loss)\n",
    "                tabnormal_score.append(ttest_loss)\n",
    "                cabnormal_score.append(cresidual_loss)\n",
    "                ground_truths.append(gt[_][j])\n",
    "            if cfg.show_heatmap:\n",
    "                # Save heatmaps and images (implementation truncated)\n",
    "                pass\n",
    "            if video_id == video_num and num_frames == len(sabnormal_score):\n",
    "                meter.update(sabnormal_score, tabnormal_score, cabnormal_score, ground_truths)\n",
    "    return meter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§© Model Module Overview\n",
    "This module defines the core building blocks of the STARGA architecture, including both generator and critic (discriminator) networks for the temporal and spatial components of video anomaly detection. The models leverage convolutional layers, instance normalization, spectral normalization, and other standard deep learning layers to ensure stable and effective training.\n",
    "\n",
    "## ðŸ”¨ Core Building Blocks\n",
    "### ðŸ”„ DoubleConv\n",
    "Purpose: Implements two consecutive convolutional layers, each followed by instance normalization and ReLU activation.\n",
    "\n",
    "Enhancement: Uses spectral normalization on each convolution to stabilize training.\n",
    "\n",
    "### â¬‡ï¸ Down\n",
    "Purpose: Reduces the spatial resolution of feature maps using MaxPooling followed by a DoubleConv block.\n",
    "\n",
    "Use: Typically employed in the encoder portion of the network.\n",
    "\n",
    "### â¬†ï¸ Up\n",
    "Purpose: Upsamples feature maps (using bilinear interpolation or transposed convolution) and concatenates them with corresponding encoder features to refine the output.\n",
    "\n",
    "Use: Commonly used in the decoder part of U-Net-like architectures.\n",
    "\n",
    "### ðŸ”š OutConv\n",
    "Purpose: Applies a final convolution with a Tanh activation to produce the output image, ensuring the output pixel values fall within a desired range.\n",
    "\n",
    "## ðŸŽ¬ Model Architectures\n",
    "### â±ï¸ Temporal Generator\n",
    "Input: Concatenation of two frames (e.g., a background and a current frame) for temporal processing.\n",
    "\n",
    "Noise Injection: Adds noise scaled by the training progress (iteration/total_iterations) to improve robustness.\n",
    "\n",
    "Architecture: An encoder-decoder structure with multiple downsampling and upsampling stages, ending with a Tanh-activated output to generate the temporal frame difference.\n",
    "\n",
    "### âš–ï¸ Temporal Critic\n",
    "Input: A generated or real temporal frame difference (3 channels).\n",
    "\n",
    "Architecture: A series of convolutional layers with increasing feature map depth, dropout for regularization, and spectral normalization to constrain the discriminator.\n",
    "\n",
    "Output: A scalar map (using a Sigmoid activation) indicating the realism of the input.\n",
    "\n",
    "### ðŸ–¼ï¸ Spatial Generator\n",
    "Input: A single frame (e.g., the current RGB frame) for spatial processing.\n",
    "\n",
    "Noise Injection: Similar to the temporal generator, noise is added based on training progress.\n",
    "\n",
    "Architecture: Follows an encoder-decoder design with downsampling and upsampling blocks, concluding with a Tanh-activated output to produce a single-channel spatial representation (e.g., an edge map).\n",
    "\n",
    "### ðŸ“ Spatial Critic\n",
    "Input: A generated or real spatial frame (1 channel).\n",
    "\n",
    "Architecture: Composed of convolutional layers with spectral normalization and dropout, ending in a Sigmoid-activated layer to assess the realism of the spatial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.331407Z",
     "iopub.status.busy": "2025-04-19T06:01:06.331181Z",
     "iopub.status.idle": "2025-04-19T06:01:06.337689Z",
     "shell.execute_reply": "2025-04-19T06:01:06.336888Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.331388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)),\n",
    "            nn.InstanceNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            spectral_norm(nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class TemporalGenerator(nn.Module):\n",
    "    def __init__(self, n_channels=6, n_classes=3, bilinear=False):\n",
    "        super(TemporalGenerator, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    def forward(self, frame1, frame2, iteration, total_iterations):\n",
    "        noise_std = max(0.1, 1 - iteration / total_iterations)\n",
    "        x = torch.cat([frame1, frame2], dim=1)\n",
    "        noise = torch.randn_like(x) * noise_std\n",
    "        x = torch.clamp(x + noise, -1, 1)\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "class TemporalCritic(nn.Module):\n",
    "    def __init__(self, input_channels=3, feature_maps=64, dropout_prob=0.3):\n",
    "        super(TemporalCritic, self).__init__()\n",
    "        self.conv1 = spectral_norm(nn.Conv2d(input_channels, feature_maps, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(feature_maps, feature_maps * 2, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(feature_maps * 2, feature_maps * 4, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(feature_maps * 4, feature_maps * 8, kernel_size=4, stride=2, padding=1))\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.output_layer = spectral_norm(nn.Conv2d(feature_maps * 8, 1, kernel_size=1, stride=1, padding=0))\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.conv4(x), 0.2)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "class SpatialGenerator(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=False):\n",
    "        super(SpatialGenerator, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    def forward(self, x, iteration, total_iterations):\n",
    "        noise_std = max(0.1, 1 - iteration / total_iterations)\n",
    "        noise = torch.randn_like(x) * noise_std\n",
    "        x = torch.clamp(x + noise, -1, 1)\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "class SpatialCritic(nn.Module):\n",
    "    def __init__(self, input_channels=1, feature_maps=64,dropout_prob=0.3):\n",
    "        super(SpatialCritic, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with increasing depth\n",
    "        self.conv1 = spectral_norm(nn.Conv2d(input_channels, feature_maps, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(feature_maps, feature_maps * 2, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(feature_maps * 2, feature_maps * 4, kernel_size=4, stride=2, padding=1))\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(feature_maps * 4, feature_maps * 8, kernel_size=4, stride=2, padding=1))\n",
    "        # Dropout layers\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # Output layer\n",
    "        self.output_layer = spectral_norm(nn.Conv2d(feature_maps * 8, 1, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # noise = torch.randn_like(x) * (1 - iteration / total_iterations)\n",
    "        # x = x + noise\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.leaky_relu(self.conv4(x), 0.2)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.418838Z",
     "iopub.status.busy": "2025-04-19T06:01:06.418561Z",
     "iopub.status.idle": "2025-04-19T06:01:06.425195Z",
     "shell.execute_reply": "2025-04-19T06:01:06.424124Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.418816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, average_precision_score, roc_curve, auc\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def min_max_normalize(arr, eps=1e-8):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    denominator = max_val - min_val + eps\n",
    "    normalized_arr = (arr - min_val) / denominator   \n",
    "    return 1- normalized_arr\n",
    "\n",
    "def evaluate(labels, scores, metric='roc'):\n",
    "    if metric == 'roc':\n",
    "        return roc(labels, scores)\n",
    "    elif metric == 'auprc':\n",
    "        return auprc(labels, scores)\n",
    "    elif metric == 'online_search':\n",
    "        return find_best_cri(labels, scores)\n",
    "    elif metric == 'combine':\n",
    "        roc_auc, fpr, tpr, threshold = roc(labels, scores,'results/')\n",
    "        scores = min_max_normalize(scores)\n",
    "        y_pred_binary = (scores >= 0.5).astype(int)\n",
    "      \n",
    "        precision = precision_score(labels, y_pred_binary, zero_division=0)\n",
    "        recall = recall_score(labels, y_pred_binary, zero_division=0)\n",
    "        f1 = f1_score(labels, y_pred_binary, zero_division=0)\n",
    "        acc = accuracy_score(labels, y_pred_binary)\n",
    "        pr_auc = average_precision_score(labels, y_pred_binary)\n",
    "\n",
    "        metrics = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'accuracy': acc,\n",
    "            'pr_auc': pr_auc\n",
    "        }\n",
    "        best_cri, best_rec, best_threshold = find_best_cri(labels, scores,threshold)\n",
    "        return roc_auc, best_cri, best_rec, fpr, tpr, best_threshold, metrics\n",
    "    else:\n",
    "        raise NotImplementedError(\"Check the evaluation metric.\")\n",
    "\n",
    "def roc(labels, scores, saveto=None):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores, pos_label=0)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    if saveto:\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='(AUC = %0.2f, EER = %0.2f)' % (roc_auc, eer))\n",
    "        plt.plot([eer], [1-eer], marker='o', markersize=5, color=\"navy\")\n",
    "        plt.plot([0, 1], [1, 0], color='navy', lw=1, linestyle=':')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(saveto, \"ROC.pdf\"))\n",
    "        plt.close()\n",
    "\n",
    "    return roc_auc, fpr, tpr,_\n",
    "\n",
    "def auprc(labels, scores):\n",
    "    ap = average_precision_score(labels, scores)\n",
    "    return ap\n",
    "\n",
    "def find_best_cri(labels, scores, thresholdtemp):\n",
    "    best_cri = -1\n",
    "    best_rec = []\n",
    "    best_threshold = -1\n",
    "    for threshold in np.arange(0, 2.001, 0.001):\n",
    "        scores_tmp = (scores >= threshold).astype(np.float32)\n",
    "\n",
    "        rec_abno = np.sum(labels * scores_tmp) / np.sum(labels)\n",
    "        rec_norm = np.sum((1 - labels) * (1 - scores_tmp)) / np.sum(1 - labels)\n",
    "        cri = (rec_norm + rec_abno) / 2\n",
    "\n",
    "        if cri > best_cri:\n",
    "            best_cri = cri\n",
    "            best_rec = [rec_norm, rec_abno]\n",
    "            best_threshold = threshold\n",
    "\n",
    "           \n",
    "\n",
    "    return best_cri, best_rec, best_threshold\n",
    "\n",
    "def l1_loss(input, target):\n",
    "    return torch.mean(torch.abs(input - target))\n",
    "\n",
    "def l2_loss(input, target, size_average=True):\n",
    "    if size_average:\n",
    "        return torch.mean(torch.pow((input - target), 2))\n",
    "    else:\n",
    "        return torch.pow((input - target), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Meter_AnoGAN:\n",
    "    def __init__(self):\n",
    "        self.gt_labels = []\n",
    "        self.sabnormal_score = []\n",
    "        self.tabnormal_score = []\n",
    "        self.cabnormal_score = []\n",
    "\n",
    "    def update(self, sloss, tloss, closs, label):\n",
    "        for k in range(len(sloss)):\n",
    "            self.sabnormal_score.append(sloss[k])\n",
    "            self.tabnormal_score.append(tloss[k])\n",
    "            self.cabnormal_score.append(closs[k])\n",
    "            self.gt_labels.append(label[k])\n",
    "    def min_max_normalize(arr, eps=1e-8):\n",
    "        min_val = np.min(arr)\n",
    "        max_val = np.max(arr)\n",
    "        denominator = max_val - min_val + eps\n",
    "        normalized_arr = (arr - min_val) / denominator\n",
    "        return 1- normalized_arr\n",
    "    def get_metrics(self):\n",
    "        self.gt_labels = torch.Tensor(self.gt_labels).int()\n",
    "        self.sabnormal_score = torch.Tensor(self.sabnormal_score)\n",
    "        self.tabnormal_score = torch.Tensor(self.tabnormal_score)\n",
    "        self.cabnormal_score = torch.Tensor(self.cabnormal_score)\n",
    "\n",
    "        sabnormal_score = (self.sabnormal_score - torch.min(self.sabnormal_score)) / (\n",
    "            torch.max(self.sabnormal_score) - torch.min(self.sabnormal_score))\n",
    "        tabnormal_score = (self.tabnormal_score - torch.min(self.tabnormal_score)) / (\n",
    "            torch.max(self.tabnormal_score) - torch.min(self.tabnormal_score))\n",
    "        cabnormal_score = (self.cabnormal_score - torch.min(self.cabnormal_score)) / (\n",
    "            torch.max(self.cabnormal_score) - torch.min(self.cabnormal_score))\n",
    "\n",
    "        self.gt_labels = self.gt_labels.numpy()\n",
    "        sabnormal_score = sabnormal_score.numpy()\n",
    "        tabnormal_score = tabnormal_score.numpy()\n",
    "        cabnormal_score = cabnormal_score.numpy()\n",
    "\n",
    "        scriterion = evaluate(self.gt_labels, sabnormal_score, metric='combine')\n",
    "        tcriterion = evaluate(self.gt_labels, tabnormal_score, metric='combine')\n",
    "        ccriterion = evaluate(self.gt_labels, cabnormal_score, metric='combine')\n",
    "\n",
    "        sbest_threshold = scriterion[5]\n",
    "        tbest_threshold = tcriterion[5]\n",
    "        cbest_threshold = ccriterion[5]\n",
    "\n",
    "        spred_labels = (sabnormal_score > sbest_threshold).astype(np.float32)\n",
    "        tpred_labels = (tabnormal_score > tbest_threshold).astype(np.float32)\n",
    "        cpred_labels = (cabnormal_score > cbest_threshold).astype(np.float32)\n",
    "\n",
    "        sres, tres, cres = [], [], []\n",
    "        for pred, gt in zip(spred_labels, self.gt_labels):\n",
    "            sres.append('TP' if gt == 0 and pred == 0 else 'FP' if gt == 0 and pred == 1 else 'FN' if gt == 1 and pred == 0 else 'TN')\n",
    "        for pred, gt in zip(tpred_labels, self.gt_labels):\n",
    "            tres.append('TP' if gt == 0 and pred == 0 else 'FP' if gt == 0 and pred == 1 else 'FN' if gt == 1 and pred == 0 else 'TN')\n",
    "        for pred, gt in zip(cpred_labels, self.gt_labels):\n",
    "            cres.append('TP' if gt == 0 and pred == 0 else 'FP' if gt == 0 and pred == 1 else 'FN' if gt == 1 and pred == 0 else 'TN')\n",
    "\n",
    "        cm = confusion_matrix(self.gt_labels, tpred_labels)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.savefig(\"confusion_matrix.png\", dpi=300)\n",
    "         # Extract metrics\n",
    "        s_metrics = scriterion[-1]\n",
    "        t_metrics = tcriterion[-1]\n",
    "        c_metrics = ccriterion[-1]\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"\\nSpatial Stream Metrics:\")\n",
    "        for k, v in s_metrics.items():\n",
    "            print(f\"{k.capitalize()}: {v:.4f}\")\n",
    "\n",
    "        print(\"\\nTemporal Stream Metrics:\")\n",
    "        for k, v in t_metrics.items():\n",
    "            print(f\"{k.capitalize()}: {v:.4f}\")\n",
    "\n",
    "        print(\"\\nCombined Stream Metrics:\")\n",
    "        for k, v in c_metrics.items():\n",
    "            print(f\"{k.capitalize()}: {v:.4f}\")\n",
    "\n",
    "        # Log to file\n",
    "        with open(\"metrics_log.txt\", \"w\") as f:\n",
    "            f.write(\"=== Spatial Stream Metrics ===\\n\")\n",
    "            for k, v in s_metrics.items():\n",
    "                f.write(f\"{k.capitalize()}: {v:.4f}\\n\")\n",
    "\n",
    "            f.write(\"\\n=== Temporal Stream Metrics ===\\n\")\n",
    "            for k, v in t_metrics.items():\n",
    "                f.write(f\"{k.capitalize()}: {v:.4f}\\n\")\n",
    "\n",
    "            f.write(\"\\n=== Combined Stream Metrics ===\\n\")\n",
    "            for k, v in c_metrics.items():\n",
    "                f.write(f\"{k.capitalize()}: {v:.4f}\\n\")\n",
    "\n",
    "        # Visualize\n",
    "        metric_names = list(s_metrics.keys())\n",
    "        x = np.arange(len(metric_names))\n",
    "        width = 0.25\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.bar(x - width, [s_metrics[m] for m in metric_names], width, label='Spatial')\n",
    "        ax.bar(x,         [t_metrics[m] for m in metric_names], width, label='Temporal')\n",
    "        ax.bar(x + width, [c_metrics[m] for m in metric_names], width, label='Combined')\n",
    "\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title('Performance Metrics by Stream')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([m.replace('_', ' ').capitalize() for m in metric_names])\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"metrics_barplot.png\", dpi=300)\n",
    "        return (\n",
    "            scriterion, sres,\n",
    "            tcriterion, tres,\n",
    "            ccriterion, cres\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Utils Module Overview\n",
    "This module provides a collection of helper functions that support the training and evaluation of the video anomaly detection model. The utilities include functions for reproducibility, logging, evaluation metrics, weight initialization, and color wheel generation for optical flow visualization.\n",
    "\n",
    "## ðŸ”’ Reproducibility & Logging\n",
    "### seed:\n",
    "Sets random seeds for Pythonâ€™s random, NumPy, and PyTorch to ensure reproducible experiments. It also configures CuDNN for deterministic behavior.\n",
    "\n",
    "### print_infor:\n",
    "Logs configuration and dataloader information such as data size, batch size, number of steps per epoch, and total iterations. This helps verify that the training environment is correctly set up.\n",
    "\n",
    "## ðŸ“Š Evaluation Metrics\n",
    "### get_metrics:\n",
    "Computes evaluation metrics such as ROC-AUC and Average Precision (AP) using predictions and ground truth labels.\n",
    "\n",
    "### psnr_error:\n",
    "Calculates the Peak Signal-to-Noise Ratio (PSNR) error between generated frames and ground truth frames. This metric is useful to assess the quality of generated images.\n",
    "\n",
    "### log10:\n",
    "A helper function to compute the logarithm base-10 of a tensor value, used within the PSNR computation.\n",
    "\n",
    "## ðŸ”§ Weight Initialization\n",
    "###  weights_init_normal:\n",
    "Initializes the weights of convolutional, linear, and batch normalization layers using methods like Kaiming or Xavier initialization.\n",
    "\n",
    "transformer_init_weights, init_linear_weights, init_layer_norm_weights, init_embedding_weights:\n",
    "Specialized functions for initializing weights of different module types, ensuring that models start with a suitable parameter distribution.\n",
    "\n",
    "## ðŸ”„ Loading & Logging Scores\n",
    "###  load_scores:\n",
    "Loads previously saved training scores (e.g., iteration number, loss lists, best AUC) from a checkpoint. This enables resuming training or evaluating past performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.705317Z",
     "iopub.status.busy": "2025-04-19T06:01:06.705067Z",
     "iopub.status.idle": "2025-04-19T06:01:06.710857Z",
     "shell.execute_reply": "2025-04-19T06:01:06.709889Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.705299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def seed(seed_value):\n",
    "    if seed_value == -1:\n",
    "        return\n",
    "\n",
    "    # Otherwise seed all functionality\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "def print_infor(cfg, dataloader):\n",
    "    cfg.epoch_size = cfg.generator_iters // len(dataloader)\n",
    "    cfg.print_cfg() \n",
    "\n",
    "    print('\\n===========================================================')\n",
    "    print('Dataloader Ok!')\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('[Data Size]:',len(dataloader.dataset))\n",
    "    print('[Batch Size]:',cfg.batch_size)\n",
    "    print('[One epoch]:',len(dataloader),'step   # (Data Size / Batch Size)')\n",
    "    print('[Epoch & Iteration]:',cfg.epoch_size,'epoch &', cfg.generator_iters,'step')\n",
    "    print('-----------------------------------------------------------')\n",
    "    print('===========================================================')\n",
    "\n",
    "def view_loss(cfg, scores):\n",
    "    tg_loss_list = scores['dg_loss_list']\n",
    "    sg_loss_list = scores['fg_loss_list']\n",
    "    td_loss_list = scores['dd_loss_list']\n",
    "    sd_loss_list = scores['fd_loss_list']\n",
    "\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.title(\"Temporal Generator and Critic Loss During Training\")\n",
    "    plt.plot(tg_loss_list,label=\"TG\")\n",
    "    plt.plot(td_loss_list,label=\"TD\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # save\n",
    "    file_path = f'results/loss_temporal_graph_{cfg.dataset}.png'\n",
    "    plt.savefig(file_path)\n",
    "    plt.cla()\n",
    "\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.title(\"Spatial Generator and Critic Loss During Training\")\n",
    "    plt.plot(sg_loss_list,label=\"SG\")\n",
    "    plt.plot(sd_loss_list,label=\"SD\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # save\n",
    "    file_path = f'results/loss_spatial_graph_{cfg.dataset}.png'\n",
    "    plt.savefig(file_path)\n",
    "    plt.cla()\n",
    "\n",
    "\n",
    "def load_scores(cfg):\n",
    "    if cfg.resume:\n",
    "        step = torch.load(cfg.resume)['step']\n",
    "        iter_list = torch.load(cfg.resume)['iter_list']\n",
    "        best_auc = torch.load(cfg.resume)['best_auc']\n",
    "        auc_list = torch.load(cfg.resume)['auc_list']\n",
    "        g_loss_list = torch.load(cfg.resume)['g_loss_list']\n",
    "        d_loss_list = torch.load(cfg.resume)['d_loss_list']\n",
    "    else:\n",
    "        step = 0\n",
    "        iter_list = []\n",
    "        best_auc = 0\n",
    "        auc_list= []\n",
    "        g_loss_list = []\n",
    "        d_loss_list = []\n",
    "\n",
    "    scores = dict()\n",
    "    scores['step'] = step\n",
    "    scores['iter_list'] = iter_list\n",
    "    scores['best_auc'] = best_auc\n",
    "    scores['auc_list'] = auc_list\n",
    "    scores['g_loss_list'] = g_loss_list\n",
    "    scores['d_loss_list'] = d_loss_list\n",
    "\n",
    "    return scores\n",
    "def get_metrics(frame_predict, frame_gt):\n",
    "    metrics = {}\n",
    "    fpr, tpr, _ = roc_curve(frame_gt, frame_predict)\n",
    "    metrics['AUC'] = auc(fpr, tpr)\n",
    "    precision, recall, th = precision_recall_curve(frame_gt, frame_predict)\n",
    "    metrics['AP'] = auc(recall, precision)\n",
    "    return metrics\n",
    "\n",
    "def log10(t):\n",
    "    numerator = torch.log(t)\n",
    "    denominator = torch.log(torch.FloatTensor([10.])).cuda()\n",
    "    return numerator / denominator\n",
    "\n",
    "def psnr_error(gen_frames, gt_frames):\n",
    "    shape = list(gen_frames.shape)\n",
    "    num_pixels = (shape[1] * shape[2] * shape[3])\n",
    "    gt_frames = (gt_frames + 1.0) / 2.0\n",
    "    gen_frames = (gen_frames + 1.0) / 2.0\n",
    "    square_diff = (gt_frames - gen_frames) ** 2\n",
    "    batch_errors = 10 * log10(1. / ((1. / num_pixels) * torch.sum(square_diff, [1, 2, 3])))\n",
    "    return torch.mean(batch_errors)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def transformer_init_weights(module):\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        init_linear_weights(module)\n",
    "    elif isinstance(module, torch.nn.LayerNorm):\n",
    "        init_layer_norm_weights(module)\n",
    "    elif isinstance(module, torch.nn.Embedding):\n",
    "        init_embedding_weights(module)\n",
    "    elif isinstance(module, torch.nn.Parameter):\n",
    "        torch.nn.init.normal_(module, mean=0, std=0.02)\n",
    "\n",
    "def init_linear_weights(linear_layer):\n",
    "    torch.nn.init.xavier_uniform_(linear_layer.weight)\n",
    "    if linear_layer.bias is not None:\n",
    "        torch.nn.init.zeros_(linear_layer.bias)\n",
    "\n",
    "def init_layer_norm_weights(layer_norm):\n",
    "    torch.nn.init.ones_(layer_norm.weight)\n",
    "    torch.nn.init.zeros_(layer_norm.bias)\n",
    "\n",
    "def init_embedding_weights(embedding_layer):\n",
    "    torch.nn.init.normal_(embedding_layer.weight, mean=0, std=embedding_layer.embedding_dim ** -0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Train Evaluation Module Overview\n",
    "This module provides functionality to evaluate the model during training. It computes various anomaly scores using generated temporal and spatial outputs, aggregates them with ground truth labels, and calculates evaluation metrics (such as ROC-AUC) for model performance. The module also logs the results and saves graphs for later inspection.\n",
    "\n",
    "## ðŸ” Key Functions\n",
    "### min_max_normalize\n",
    "Purpose:\n",
    "Normalizes a NumPy array to the range [0, 1] using its minimum and maximum values.\n",
    "\n",
    "Usage:\n",
    "Useful for standardizing anomaly scores before evaluation.\n",
    "\n",
    "### val_train_eval\n",
    "Purpose:\n",
    "Evaluates the current model on the test dataset during training.\n",
    "\n",
    "## Process Overview:\n",
    "\n",
    "### Dataset Loading:\n",
    "\n",
    "Lists test video folders and sorts them.\n",
    "\n",
    "Creates a custom test dataset and DataLoader.\n",
    "\n",
    "Ground Truth Preparation:\n",
    "\n",
    "Loads ground truth anomaly labels using Label_loader.\n",
    "\n",
    "### Score Computation:\n",
    "\n",
    "Iterates over each video clip in the test dataset.\n",
    "\n",
    "For each frame in a video:\n",
    "\n",
    "Generates fake temporal and spatial frames using the current model.\n",
    "\n",
    "Computes PSNR-based losses between generated frames and their corresponding ground truth frames.\n",
    "\n",
    "Aggregates separate scores for spatial, temporal, and combined (residual) anomalies.\n",
    "\n",
    "### Metric Aggregation:\n",
    "\n",
    "Uses a custom meter (here, Meter_AnoGAN) to update and retrieve evaluation metrics such as SAUC (spatial AUC), TAUC (temporal AUC), and CAUC (combined AUC).\n",
    "\n",
    "### Logging & Graphing:\n",
    "\n",
    "Logs the current evaluation scores to a text file.\n",
    "\n",
    "Saves graphs of the evaluation metrics across iterations for visualization.\n",
    "\n",
    "Returns:\n",
    "The function returns the spatial and temporal AUC scores along with updated training scores.\n",
    "\n",
    "## ðŸ”§ Integration\n",
    "### Device Management:\n",
    "The module uses the designated device (CPU or GPU) for all computations.\n",
    "\n",
    "### Model Access:\n",
    "The evaluation function accesses the model components (i.e., TemporalGenerator and SpatialGenerator) from the training object (self), enabling a seamless evaluation of the current training state.\n",
    "\n",
    "### Metric Calculation:\n",
    "Uses PSNR-based errors as a proxy for image quality to compute anomaly scores. These scores are then aggregated and converted into evaluation metrics using helper functions and the Meter_AnoGAN class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:06.712454Z",
     "iopub.status.busy": "2025-04-19T06:01:06.712173Z",
     "iopub.status.idle": "2025-04-19T06:01:06.730919Z",
     "shell.execute_reply": "2025-04-19T06:01:06.730060Z",
     "shell.execute_reply.started": "2025-04-19T06:01:06.712425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_eval.py\n",
    "import os\n",
    "import torch \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from dataset import Label_loader\n",
    "import dataset\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluate import *\n",
    "from torchvision.utils import save_image\n",
    "from save_func import * \n",
    "\n",
    "def min_max_normalize(arr, eps=1e-8):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    denominator = max_val - min_val + eps\n",
    "    normalized_arr = (arr - min_val) / denominator\n",
    "    return 1- normalized_arr\n",
    "\n",
    "def val_train_eval(self, cfg, train_scores, iter):\n",
    "    dataset_name = cfg.dataset\n",
    "    video_folders = os.listdir(cfg.test_data)\n",
    "    video_folders.sort()\n",
    "    video_folders = [os.path.join(cfg.test_data, aa) for aa in video_folders]\n",
    "    abnormaltest_dataset = dataset.test_dataset(cfg)\n",
    "    abnormaltest_dataloader = DataLoader(dataset=abnormaltest_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    meter = Meter_AnoGAN()\n",
    "    self.l_con = l1_loss\n",
    "    self.l_enc = l2_loss\n",
    "    psnrs = []\n",
    "    psnr_group = []\n",
    "    sauc = 0\n",
    "    tauc = 0\n",
    "    tfake_scores = []\n",
    "    y_true = []\n",
    "    sfake_scores = []\n",
    "    gt_loader = Label_loader(cfg, video_folders)\n",
    "    gt = gt_loader()\n",
    "    criterion = nn.MSELoss(reduction='none')\n",
    "    video_num = 0\n",
    "    sabnormal_score = []\n",
    "    tabnormal_score = []\n",
    "    cabnormal_score = []\n",
    "    ground_truths = []\n",
    "    edge_scores = []\n",
    "    diff_scores = []\n",
    "    with torch.no_grad():\n",
    "        for _, [clips, diff_frames, edge_frames, background_image, video_id, num_frames] in enumerate(abnormaltest_dataloader):\n",
    "            if video_id != video_num:\n",
    "                video_num = video_id\n",
    "                sabnormal_score = []\n",
    "                tabnormal_score = []\n",
    "                cabnormal_score = []\n",
    "                ground_truths = []\n",
    "                edge_scores = []\n",
    "                diff_scores = []\n",
    "            real_video = clips.to(device)\n",
    "            for j in range(len(clips[0])):\n",
    "                real_frame = real_video[:, j, :, :, :]\n",
    "                diff_frame = diff_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                edge_frame = edge_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                background_image = background_image.to(device)\n",
    "                fake_temporal_frame = self.TemporalGenerator(background_image, real_frame, iter, cfg.generator_iters).detach()\n",
    "                fake_spatial_frame = self.SpatialGenerator(real_frame, iter, cfg.generator_iters).detach()\n",
    "                stest_loss = float(psnr_error(fake_spatial_frame, edge_frame).cpu().detach().numpy())\n",
    "                ttest_loss = float(psnr_error(fake_temporal_frame, diff_frame).cpu().detach().numpy())\n",
    "                alpha = 0.0\n",
    "                cresidual_loss = stest_loss + ttest_loss\n",
    "                sabnormal_score.append(stest_loss)\n",
    "                tabnormal_score.append(ttest_loss)\n",
    "                cabnormal_score.append(cresidual_loss)\n",
    "                ground_truths.append(gt[_][j])\n",
    "            if video_id == video_num and num_frames == len(sabnormal_score):\n",
    "                meter.update(sabnormal_score, tabnormal_score, cabnormal_score, ground_truths)\n",
    "    scriterion, sres_total, tcriterion, tres_total, ccriterion, cres_total = meter.get_metrics()\n",
    "    sauc = scriterion[0]\n",
    "    tauc = tcriterion[0]\n",
    "    cauc = ccriterion[0]\n",
    "    print(f\"sauc: {sauc} | tauc: {tauc} | cauc: {cauc}\")\n",
    "    train_scores['iter_list'].append(iter)\n",
    "    train_scores['sauc_list'].append(sauc)\n",
    "    train_scores['tauc_list'].append(tauc)\n",
    "    save_text(f\"[{dataset_name}][{iter}] SAUC: {sauc}  TAUC: {tauc}  CAUC: {cauc}\", f'results/auc_{dataset_name}.txt')\n",
    "    save_auc_graph_train(iters=train_scores['iter_list'], scores=train_scores['sauc_list'],\n",
    "                         file_path=f'results/sauc_{dataset_name}.jpg')\n",
    "    save_auc_graph_train(iters=train_scores['iter_list'], scores=train_scores['tauc_list'],\n",
    "                         file_path=f'results/tauc_{dataset_name}.jpg')\n",
    "    return sauc, tauc, train_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”Ž Test Evaluation Module Overview\n",
    "This module evaluates the trained video anomaly detection model on the test set. It computes per-frame anomaly scores using PSNR-based metrics from the generated spatial and temporal outputs, logs and saves visualizations (such as real/fake images and heatmaps), and aggregates the results to calculate ROC-AUC and other performance metrics.\n",
    "\n",
    "## ðŸ› ï¸ Utility Functions\n",
    "### min_max_normalize:\n",
    "Normalizes a NumPy array to the range [0, 1] by subtracting the minimum and dividing by the range.\n",
    "Usage: Standardizes scores before visualization or further processing.\n",
    "\n",
    "### psnr_park:\n",
    "Computes the Peak Signal-to-Noise Ratio (PSNR) from a mean squared error (MSE) value.\n",
    "Usage: Used as an indicator of image quality, where higher PSNR reflects better similarity between generated and ground-truth images.\n",
    "\n",
    "## ðŸ“š Data & Ground Truth Preparation\n",
    "### Dataset Loading:\n",
    "The module lists and sorts video folders from the test directory and creates a custom test dataset along with a DataLoader for efficient iteration.\n",
    "\n",
    "### Ground Truth Retrieval:\n",
    "Uses Label_loader from the dataset module to load ground truth anomaly labels corresponding to each test video.\n",
    "\n",
    "## ðŸŽ¥ Evaluation Procedure\n",
    "Within the main evaluation function val_test_eval:\n",
    "\n",
    "Iterating Over Test Videos:\n",
    "\n",
    "The DataLoader iterates over each test video clip, providing:\n",
    "\n",
    "Clips: The original video frames.\n",
    "\n",
    "Diff Frames: Pre-computed frame-difference images.\n",
    "\n",
    "Edge Frames: Spatial representations (e.g., edge maps).\n",
    "\n",
    "Background Image: A reference background for the clip.\n",
    "\n",
    "Video ID & Total Frame Count: Used to manage and group results.\n",
    "\n",
    "Per-Frame Processing:\n",
    "For each frame in the clip:\n",
    "\n",
    "Directory Creation:\n",
    "The function ensures that directories for saving results are created (using os.makedirs) for the current iteration and frame.\n",
    "\n",
    "Model Inference:\n",
    "The current modelâ€™s generators produce:\n",
    "\n",
    "Fake Temporal Frame: Generated by processing the background and real frame.\n",
    "\n",
    "Fake Spatial Frame: Generated from the real frame.\n",
    "\n",
    "### Score Computation:\n",
    "PSNR errors are computed:\n",
    "\n",
    "Spatial Score (stest_loss): Difference between fake spatial and ground-truth edge frames.\n",
    "\n",
    "Temporal Score (ttest_loss): Difference between fake temporal and ground-truth diff frames.\n",
    "\n",
    "Combined Score: Sum of spatial and temporal scores.\n",
    "\n",
    "### Logging Ground Truth:\n",
    "Each frameâ€™s ground truth anomaly label is recorded.\n",
    "\n",
    "### Saving Visual Outputs:\n",
    "\n",
    "- Real and fake spatial images are saved after normalization (mapping values from \n",
    "âˆ’1,1 to 0,1).\n",
    "\n",
    "- Temporal outputs are rearranged (swapping channels if needed) and saved.\n",
    "\n",
    "- If the configuration flag show_heatmap is set, corresponding heatmaps are generated and saved using helper functions.\n",
    "\n",
    "### Metric Aggregation:\n",
    "\n",
    "The custom Meter_AnoGAN object accumulates the per-frame anomaly scores and ground truth labels.\n",
    "\n",
    "After processing each video, individual and aggregate scores (e.g., spatial AUC, temporal AUC, combined AUC) are computed using ROC metrics.\n",
    "\n",
    "Detailed logs, including per-frame scores and overall AUC, are saved to text files.\n",
    "\n",
    "Graphs visualizing the anomaly scores across frames are also saved.\n",
    "\n",
    "### Final Output:\n",
    "The function prints and returns the computed metrics, such as spatial, temporal, and combined AUC scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:07.208286Z",
     "iopub.status.busy": "2025-04-19T06:01:07.207880Z",
     "iopub.status.idle": "2025-04-19T06:01:07.214881Z",
     "shell.execute_reply": "2025-04-19T06:01:07.213944Z",
     "shell.execute_reply.started": "2025-04-19T06:01:07.208249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_eval.py\n",
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataset import Label_loader\n",
    "import dataset\n",
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluate import *\n",
    "import math\n",
    "from save_func import * \n",
    "from evaluate import *\n",
    "\n",
    "\n",
    "def min_max_normalize(arr, eps=1e-8):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    denominator = max_val - min_val + eps\n",
    "    normalized_arr = (arr - min_val) / denominator   \n",
    "    return 1 - normalized_arr\n",
    "def psnr_park(mse):\n",
    "    return 10 * math.log10(1 / mse)\n",
    "\n",
    "def val_test_eval(cfg, self, iter):\n",
    "    dataset_name = cfg.dataset\n",
    "    video_folders = os.listdir(cfg.test_data)\n",
    "    video_folders.sort()\n",
    "    video_folders = [os.path.join(cfg.test_data, aa) for aa in video_folders]\n",
    "    abnormaltest_dataset = dataset.test_dataset(cfg)\n",
    "    abnormaltest_dataloader = DataLoader(dataset=abnormaltest_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True)\n",
    "    meter = Meter_AnoGAN()\n",
    "    psnrs = []\n",
    "    psnr_group = []\n",
    "    auc = 0\n",
    "    fake_scores = []\n",
    "    real_scores = []\n",
    "    y_true = []\n",
    "    gt_loader = Label_loader(cfg, video_folders)\n",
    "    gt = gt_loader()\n",
    "    video_num = 0\n",
    "    sabnormal_score = []\n",
    "    tabnormal_score = []\n",
    "    cabnormal_score = []\n",
    "    ground_truths = []\n",
    "    combine_scores = []\n",
    "    with torch.no_grad():\n",
    "        for _, [clips, diff_frames, edge_frames, background_image, video_id, num_frames] in enumerate(abnormaltest_dataloader):\n",
    "            if video_id != video_num:\n",
    "                video_num = video_id\n",
    "                sabnormal_score = []\n",
    "                tabnormal_score = []\n",
    "                cabnormal_score = []\n",
    "                ground_truths = [] \n",
    "                combine_scores = []\n",
    "            real_video = clips.to(device)\n",
    "            for j in range(len(clips[0])):\n",
    "                if not os.path.exists(f\"results/{dataset_name}/{iter}/f{_+1}\"):\n",
    "                    os.makedirs(f\"results/{dataset_name}/{iter}/f{_+1}\")\n",
    "                real_frame = real_video[:, j, :, :, :]\n",
    "                diff_frame = diff_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                edge_frame = edge_frames[:, j, :, :, :].to(device).requires_grad_(True)\n",
    "                background_image = background_image.to(device)\n",
    "                fake_temporal_frame = self.TemporalGenerator(background_image, real_frame, iter, cfg.generator_iters).detach()\n",
    "                fake_spatial_frame = self.SpatialGenerator(real_frame, iter, cfg.generator_iters).detach()\n",
    "                stest_loss = float(psnr_error(fake_spatial_frame, edge_frame).cpu().detach().numpy())\n",
    "                ttest_loss = float(psnr_error(fake_temporal_frame, diff_frame).cpu().detach().numpy())\n",
    "                combine_scores.append(stest_loss + ttest_loss)\n",
    "                alpha = 0.0\n",
    "                cresidual_loss = float(psnr_error(fake_spatial_frame + fake_temporal_frame, diff_frame + edge_frame).cpu().detach().numpy())\n",
    "                sabnormal_score.append(stest_loss)\n",
    "                tabnormal_score.append(ttest_loss)\n",
    "                cabnormal_score.append(cresidual_loss)\n",
    "                ground_truths.append(gt[_][j])\n",
    "            F_spatial_frame = ((fake_spatial_frame[0].cpu() + 1) / 2).squeeze(0)\n",
    "            target_spatial_frame = ((edge_frame[0].cpu() + 1) / 2).squeeze(0)\n",
    "            save_image(target_spatial_frame, f'results/{dataset_name}/{iter}/f{_+1}/real_{_}_spatail.jpg')\n",
    "            save_image(F_spatial_frame, f'results/{dataset_name}/{iter}/f{_+1}/fake_{_}_spatail.jpg')\n",
    "            F_temporal_frame = ((fake_temporal_frame[0].cpu() + 1) / 2)[(2,1,0), ...]\n",
    "            target_temporal_frame = ((diff_frame[0].cpu() + 1) / 2)[(2,1,0), ...]\n",
    "            save_image(target_temporal_frame, f'results/{dataset_name}/{iter}/f{_+1}/real_{_}_temporal.jpg')\n",
    "            save_image(F_temporal_frame, f'results/{dataset_name}/{iter}/f{_+1}/fake_{_}_temporal.jpg')\n",
    "            if cfg.show_heatmap:\n",
    "                save_grayscale_heatmap(F_spatial_frame, target_spatial_frame, f'results/{dataset_name}/{iter}/f{_+1}/diff_{_}_spatial.jpg')\n",
    "                save_heatmap(F_temporal_frame, target_temporal_frame, f'results/{dataset_name}/{iter}/f{_+1}/diff_{_}_temporal.jpg')\n",
    "            torch.cuda.synchronize()\n",
    "            if video_id == video_num and num_frames == len(sabnormal_score):\n",
    "                meter.update(sabnormal_score, tabnormal_score, cabnormal_score, ground_truths)\n",
    "                for k in range(len(sabnormal_score)):\n",
    "                    save_text(f\"[{k}] Anomaly score : s {sabnormal_score[k]} |t {tabnormal_score[k]}|c {combine_scores[k]} | label: {ground_truths[k]}\",\n",
    "                              f'results/{dataset_name}/{iter}/{video_num}_score_label.txt')\n",
    "                anomalies_idx = [i for i, l in enumerate(ground_truths) if l == 1]\n",
    "                save_score_graph(y='Anomaly Score', answers_idx=anomalies_idx, scores=sabnormal_score,\n",
    "                                 file_path=f'results/{dataset_name}/{iter}/{video_num}_sanomaly_score.jpg')\n",
    "                save_score_graph(y='Anomaly Score', answers_idx=anomalies_idx, scores=tabnormal_score,\n",
    "                                 file_path=f'results/{dataset_name}/{iter}/{video_num}_tanomaly_score.jpg')\n",
    "                save_score_graph(y='Anomaly Score', answers_idx=anomalies_idx, scores=combine_scores,\n",
    "                                 file_path=f'results/{dataset_name}/{iter}/{video_num}_canomaly_score.jpg')\n",
    "                sfpr, stpr, thresholds = metrics.roc_curve(ground_truths, sabnormal_score, pos_label=0)\n",
    "                sauc = metrics.auc(sfpr, stpr)\n",
    "                tfpr, ttpr, thresholds = metrics.roc_curve(ground_truths, tabnormal_score, pos_label=0)\n",
    "                tauc = metrics.auc(tfpr, ttpr)\n",
    "                cfpr, ctpr, thresholds = metrics.roc_curve(ground_truths, combine_scores, pos_label=0)\n",
    "                cauc = metrics.auc(cfpr, ctpr)\n",
    "                save_text(f\"[{video_id} video] sauc: {sauc} tauc: {tauc} cauc: {cauc}\\n\", file_path=f'results/{dataset_name}/{iter}/individual_auc.txt')\n",
    "               \n",
    "            end = time.time()\n",
    "            if _ > 1:\n",
    "                fps = 30 / (end - _)\n",
    "                print(f'\\rDetecting: [{_ + 1:02d}] {_ + 1}/{len(abnormaltest_dataloader)}, {fps:.2f} fps.', end='')\n",
    "    for k in range(len(meter.gt_labels)):\n",
    "        save_text(f\"[{k}] Anomaly score s: {meter.sabnormal_score[k]} | t: {meter.tabnormal_score[k]} | c: {meter.cabnormal_score[k]} | label: {meter.gt_labels[k]}\",\n",
    "                  f'results/{dataset_name}/{iter}/score_label.txt')\n",
    "    anomalies_idx = [i for i, l in enumerate(meter.gt_labels) if l == 1]\n",
    "    save_score_graph(y='sAnomaly Score', answers_idx=anomalies_idx, scores=min_max_normalize(meter.sabnormal_score),\n",
    "                     file_path=f'results/{dataset_name}/{iter}/sanomaly_score.jpg')\n",
    "    save_score_graph(y='tAnomaly Score', answers_idx=anomalies_idx, scores=min_max_normalize(meter.tabnormal_score),\n",
    "                     file_path=f'results/{dataset_name}/{iter}/tanomaly_score.jpg')\n",
    "    save_score_graph(y='cAnomaly Score', answers_idx=anomalies_idx, scores=min_max_normalize(meter.cabnormal_score),\n",
    "                     file_path=f'results/{dataset_name}/{iter}/canomaly_score.jpg')\n",
    "    scriterion, sres_total, tcriterion, tres_total, ccriterion, cres_total = meter.get_metrics()\n",
    "    sauc = scriterion[0]\n",
    "    tauc = tcriterion[0]\n",
    "    cauc = ccriterion[0]\n",
    "    print(f\"sauc: {sauc} | tauc: {tauc} | cauc: {cauc}\")\n",
    "    save_text(f\"[{len(abnormaltest_dataloader)} video] sauc: {sauc}|tauc: {tauc} |cauc: {cauc} auc\\n\",\n",
    "              f'results/{dataset_name}/{iter}/auc.txt')\n",
    "    if cfg.show_curve:\n",
    "        save_roc_curve(scriterion[3], scriterion[4], scriterion[0],\n",
    "                       file_path=f'results/{dataset_name}/{iter}/stotal_auc_curve.jpg')\n",
    "        save_roc_curve(tcriterion[3], tcriterion[4], tcriterion[0],\n",
    "                       file_path=f'results/{dataset_name}/{iter}/ttotal_auc_curve.jpg')\n",
    "        save_roc_curve(ccriterion[3], ccriterion[4], ccriterion[0],\n",
    "                       file_path=f'results/{dataset_name}/{iter}/ctotal_auc_curve.jpg')\n",
    "    return meter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¾ Save Functions Module Overview\n",
    "This module provides helper functions to save various outputs during training and evaluation. It handles writing text logs, saving graphs for AUC scores, and generating visualizations such as heatmaps and score graphs for anomaly detection results.\n",
    "\n",
    "## ðŸ“ Text Saving\n",
    "save_text:\n",
    "Appends a given text string to a specified file.\n",
    "Usage: Logs training or evaluation messages to text files.\n",
    "\n",
    "## ðŸ“ˆ Graph Plotting\n",
    "### save_auc_graph_train:\n",
    "\n",
    "#### Functionality:\n",
    "Plots AUC scores over training iterations.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "- Clears the current plot.\n",
    "\n",
    "- Plots the iteration numbers against AUC scores using a line graph.\n",
    "\n",
    "- Identifies and marks the best (maximum) AUC score with a scatter point and text label.\n",
    "\n",
    "- Saves the resulting graph to the specified file path.\n",
    "\n",
    "Usage: Visualizing model performance trends during training.\n",
    "\n",
    "### save_score_graph:\n",
    "\n",
    "#### Functionality:\n",
    "Plots anomaly scores across frames and highlights frames corresponding to abnormal events.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "- Clears the current plot.\n",
    "\n",
    "- Plots anomaly scores as a line graph.\n",
    "\n",
    "- Overlays a bar graph on the specified abnormal frame indices.\n",
    "\n",
    "- Saves the plot for further inspection.\n",
    "\n",
    "Usage: To inspect how anomaly scores vary across a video.\n",
    "\n",
    "### save_roc_curve:\n",
    "\n",
    "#### Functionality:\n",
    "Plots the Receiver Operating Characteristic (ROC) curve using false positive and true positive rates.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "- Clears the current plot.\n",
    "\n",
    "- Plots the ROC curve and a reference diagonal line.\n",
    "\n",
    "- Labels the plot with AUC information and axis labels.\n",
    "\n",
    "- Saves the ROC curve image.\n",
    "\n",
    "Usage: To evaluate the discriminative performance of the model.\n",
    "\n",
    "## ðŸŒ¡ï¸ Heatmap Generation\n",
    "### save_heatmap:\n",
    "\n",
    "#### Functionality:\n",
    "Generates a heatmap by computing the absolute difference between two tensors (typically, generated and ground-truth frames).\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "- Computes the difference map and normalizes it to the range [0, 255].\n",
    "\n",
    "- Applies a color map (COLORMAP_JET) for better visualization.\n",
    "\n",
    "- Saves the color-mapped image.\n",
    "\n",
    "Usage: Visualizing differences between generated and target frames in color.\n",
    "\n",
    "### save_grayscale_heatmap:\n",
    "\n",
    "#### Functionality:\n",
    "Generates a grayscale heatmap by calculating the absolute difference between two images.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "- Converts tensor inputs to NumPy arrays if needed.\n",
    "\n",
    "- Scales the images to the range [0, 255] (if not already scaled).\n",
    "\n",
    "- Computes the normalized difference and saves the resulting image.\n",
    "\n",
    "Usage: For a more direct, grayscale visualization of frame differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T06:01:07.216310Z",
     "iopub.status.busy": "2025-04-19T06:01:07.216030Z",
     "iopub.status.idle": "2025-04-19T06:01:07.232927Z",
     "shell.execute_reply": "2025-04-19T06:01:07.232028Z",
     "shell.execute_reply.started": "2025-04-19T06:01:07.216284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing save_func.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_func.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import cv2\n",
    "import torch \n",
    "\n",
    "# Save text to file\n",
    "def save_text(text, file_path):\n",
    "    with open(file_path, 'a+') as file:\n",
    "        file.write(text + \"\\n\")\n",
    "\n",
    "# Save AUC graph during training\n",
    "def save_auc_graph_train(iters, scores, file_path):\n",
    "    plt.clf()\n",
    "    plt.plot(iters, scores, c='royalblue')\n",
    "    scores_np = np.array(scores)\n",
    "    best_idx = np.argmax(scores_np)\n",
    "    best_itr = iters[best_idx]\n",
    "    best_score = scores[best_idx]\n",
    "    plt.scatter([best_itr], [best_score], c='darkorange', s=25, edgecolors='royalblue')\n",
    "    plt.text(best_itr, best_score, f'{best_itr}: {best_score:.3f}', ha='left', va='bottom')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "# Save heatmap\n",
    "def save_heatmap(F_frame, target_frame, file_path):\n",
    "    diff_map = torch.sum(torch.abs(F_frame - target_frame).squeeze(), 0)\n",
    "    diff_map -= diff_map.min()\n",
    "    diff_map /= diff_map.max()\n",
    "    diff_map *= 255\n",
    "    diff_map = diff_map.cpu().detach().numpy().astype('uint8')\n",
    "    heat_map = cv2.applyColorMap(diff_map, cv2.COLORMAP_JET)\n",
    "    cv2.imwrite(file_path, heat_map)\n",
    "\n",
    "def save_grayscale_heatmap(F_frame, target_frame, file_path):\n",
    "    if isinstance(F_frame, torch.Tensor):\n",
    "        F_frame = F_frame.cpu().numpy()\n",
    "    if isinstance(target_frame, torch.Tensor):\n",
    "        target_frame = target_frame.cpu().numpy()\n",
    "    F_frame = (F_frame * 255).astype(np.uint8) if F_frame.max() <= 1 else F_frame.astype(np.uint8)\n",
    "    target_frame = (target_frame * 255).astype(np.uint8) if target_frame.max() <= 1 else target_frame.astype(np.uint8)\n",
    "    if F_frame.shape != target_frame.shape:\n",
    "        raise ValueError(\"Images must have the same dimensions\")\n",
    "    diff_map = np.abs(F_frame.astype(np.float32) - target_frame.astype(np.float32))\n",
    "    diff_map -= diff_map.min()\n",
    "    diff_map /= diff_map.max()\n",
    "    diff_map *= 255\n",
    "    diff_map = diff_map.astype(np.uint8)\n",
    "    cv2.imwrite(file_path, diff_map)\n",
    "\n",
    "def save_score_graph(answers_idx, scores, file_path, x='Frame', y='Anomaly Score'):\n",
    "    length = len(scores)\n",
    "    plt.clf()\n",
    "    plt.plot(range(length), scores)\n",
    "    plt.bar(answers_idx, max(scores), width=1, color='r', alpha=0.5)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "def save_roc_curve(fpr, tpr, auc, file_path):\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (area = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate (FRR)')\n",
    "    plt.ylabel('True Positive Rate (TRR)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve(Ped2)')\n",
    "    plt.legend()\n",
    "    plt.savefig(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Running Training from a Notebook\n",
    "This snippet demonstrates how to launch the training pipeline directly within a Jupyter Notebook by simulating command-line arguments and invoking the main training function.\n",
    "--batch_size 3: Sets the batch size to 3.\n",
    "\n",
    "--dataset ped2: Chooses the ped2 dataset.\n",
    "\n",
    "--resume '': Indicates that training should start from scratch (no pre-trained model is resumed).\n",
    "\n",
    "--save_interval 1 and --val_interval 30: Specify how often the model should be saved and evaluated.\n",
    "\n",
    "--manualseed -1: Uses a default seed (-1) for randomness.\n",
    "\n",
    "--generator_iters 20000: Sets the total number of generator iterations to 20,000.\n",
    "\n",
    "--cuda True: Enables CUDA (GPU) if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:15:15.819509Z",
     "iopub.status.busy": "2025-04-20T11:15:15.818830Z",
     "iopub.status.idle": "2025-04-20T12:06:49.927244Z",
     "shell.execute_reply": "2025-04-20T12:06:49.926006Z",
     "shell.execute_reply.started": "2025-04-20T11:15:15.819473Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "------------------------------train cfg------------------------------\n",
      "mode: train\n",
      "dataset: ped2\n",
      "img_size: (256, 256)\n",
      "root_folder: /kaggle/input/ped2-v1/\n",
      "batch_size: 4\n",
      "train_data: /kaggle/input/ped2-v1/ped2/training/frames/\n",
      "test_root_path: /kaggle/input/ped2-v1/ped2/testing/\n",
      "train_root_path: /kaggle/input/ped2-v1/ped2/training/\n",
      "test_data: /kaggle/input/ped2-v1/ped2/testing/frames/\n",
      "g_lr: 0.0002\n",
      "d_lr: 2e-05\n",
      "show_flow: False\n",
      "resume: latest_ped2\n",
      "save_interval: 1\n",
      "val_interval: 25\n",
      "manualseed: -1\n",
      "generator_iters: 20000\n",
      "cuda: True\n",
      "is_local: False\n",
      "trained_model: latest_ped2\n",
      "show_curve: True\n",
      "show_heatmap: True\n",
      "epoch_size: 277\n",
      "\n",
      "\n",
      "===========================================================\n",
      "Dataloader Ok!\n",
      "-----------------------------------------------------------\n",
      "[Data Size]: 291\n",
      "[Batch Size]: 4\n",
      "[One epoch]: 72 step   # (Data Size / Batch Size)\n",
      "[Epoch & Iteration]: 277 epoch & 20000 step\n",
      "-----------------------------------------------------------\n",
      "===========================================================\n",
      "WGAN_Stage init model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Cuda enabled flag: True\n",
      "\n",
      "===========================================================\n",
      "Training Start!\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 1/72 [00:23<27:34, 23.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1296/20000, Temporal_d_loss: 41.70318832397461 , Temporal_g_loss: 9.541973209381103   , Spatial_d_loss: 11.753301334381103, Spatial_g_loss: 7.712866973876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 2/72 [00:45<26:08, 22.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1297/20000, Temporal_d_loss: 32.57278118133545 , Temporal_g_loss: 7.932476949691773   , Spatial_d_loss: 11.68586368560791, Spatial_g_loss: 7.054404592514038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 3/72 [01:05<24:56, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1298/20000, Temporal_d_loss: 32.276221084594724 , Temporal_g_loss: 7.711462116241455   , Spatial_d_loss: 11.735787677764893, Spatial_g_loss: 6.527252721786499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 4/72 [01:26<24:13, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1299/20000, Temporal_d_loss: 32.56026954650879 , Temporal_g_loss: 7.6308385848999025   , Spatial_d_loss: 11.726197242736816, Spatial_g_loss: 6.516210889816284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 5/72 [01:48<23:50, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1300/20000, Temporal_d_loss: 35.775024604797366 , Temporal_g_loss: 9.248642349243164   , Spatial_d_loss: 11.765824317932129, Spatial_g_loss: 7.916594934463501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 6/72 [02:09<23:28, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1301/20000, Temporal_d_loss: 36.85844383239746 , Temporal_g_loss: 9.315197563171386   , Spatial_d_loss: 11.730094146728515, Spatial_g_loss: 7.613873052597046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 7/72 [02:30<23:05, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1302/20000, Temporal_d_loss: 29.82927703857422 , Temporal_g_loss: 7.542952203750611   , Spatial_d_loss: 11.73197021484375, Spatial_g_loss: 6.5427392482757565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 8/72 [02:51<22:40, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1303/20000, Temporal_d_loss: 39.52366008758545 , Temporal_g_loss: 11.130911254882813   , Spatial_d_loss: 11.722926425933839, Spatial_g_loss: 9.041935920715332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–Ž        | 9/72 [03:12<22:17, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1304/20000, Temporal_d_loss: 35.36539268493652 , Temporal_g_loss: 8.98246603012085   , Spatial_d_loss: 11.729663753509522, Spatial_g_loss: 7.487668752670288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 10/72 [03:34<21:57, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1305/20000, Temporal_d_loss: 34.22791385650635 , Temporal_g_loss: 8.880196857452393   , Spatial_d_loss: 11.712365436553956, Spatial_g_loss: 7.753354215621949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 11/72 [03:55<21:36, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1306/20000, Temporal_d_loss: 37.949838638305664 , Temporal_g_loss: 9.069098567962646   , Spatial_d_loss: 11.689323043823242, Spatial_g_loss: 7.675903987884522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 12/72 [04:16<21:13, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1307/20000, Temporal_d_loss: 35.43451042175293 , Temporal_g_loss: 9.248591136932372   , Spatial_d_loss: 11.68515920639038, Spatial_g_loss: 7.621918058395385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 13/72 [04:37<20:48, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1308/20000, Temporal_d_loss: 28.92723503112793 , Temporal_g_loss: 6.562976551055908   , Spatial_d_loss: 11.710814380645752, Spatial_g_loss: 5.769617891311645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 14/72 [04:58<20:26, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1309/20000, Temporal_d_loss: 38.25017967224121 , Temporal_g_loss: 8.707678890228271   , Spatial_d_loss: 11.726927566528321, Spatial_g_loss: 7.492776250839233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 15/72 [05:20<20:05, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1310/20000, Temporal_d_loss: 45.801859092712405 , Temporal_g_loss: 12.976380634307862   , Spatial_d_loss: 11.689565753936767, Spatial_g_loss: 10.082122993469238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 16/72 [05:41<19:46, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1311/20000, Temporal_d_loss: 34.46481914520264 , Temporal_g_loss: 9.031924629211426   , Spatial_d_loss: 11.776936626434326, Spatial_g_loss: 7.308988952636719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 17/72 [06:02<19:26, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1312/20000, Temporal_d_loss: 37.48928337097168 , Temporal_g_loss: 9.416110610961914   , Spatial_d_loss: 11.674046611785888, Spatial_g_loss: 7.565890502929688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 18/72 [06:23<19:05, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1313/20000, Temporal_d_loss: 37.4832145690918 , Temporal_g_loss: 9.331453132629395   , Spatial_d_loss: 11.719835090637208, Spatial_g_loss: 7.510921430587769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–‹       | 19/72 [06:45<18:44, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1314/20000, Temporal_d_loss: 34.4762466430664 , Temporal_g_loss: 10.74632568359375   , Spatial_d_loss: 11.723561859130859, Spatial_g_loss: 8.614111709594727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 20/72 [07:06<18:23, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1315/20000, Temporal_d_loss: 34.275123023986815 , Temporal_g_loss: 9.269960689544678   , Spatial_d_loss: 11.709708404541015, Spatial_g_loss: 7.6363190650939945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 21/72 [07:27<18:01, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1316/20000, Temporal_d_loss: 34.69876651763916 , Temporal_g_loss: 8.162325000762939   , Spatial_d_loss: 11.758263111114502, Spatial_g_loss: 7.1710456848144535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 22/72 [07:48<17:39, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1317/20000, Temporal_d_loss: 34.441849899291995 , Temporal_g_loss: 9.2838303565979   , Spatial_d_loss: 11.693587684631348, Spatial_g_loss: 7.808694314956665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 23/72 [08:09<17:18, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1318/20000, Temporal_d_loss: 40.6005781173706 , Temporal_g_loss: 10.473308753967284   , Spatial_d_loss: 11.699409484863281, Spatial_g_loss: 9.129102039337159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24/72 [08:31<16:57, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1319/20000, Temporal_d_loss: 29.7769495010376 , Temporal_g_loss: 7.8073601722717285   , Spatial_d_loss: 11.74864902496338, Spatial_g_loss: 6.718667030334473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 25/72 [08:52<16:36, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1320/20000, Temporal_d_loss: 40.95980854034424 , Temporal_g_loss: 11.509464073181153   , Spatial_d_loss: 11.720138645172119, Spatial_g_loss: 9.016075801849365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/72 [09:13<16:16, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1321/20000, Temporal_d_loss: 32.9233419418335 , Temporal_g_loss: 7.229270505905151   , Spatial_d_loss: 11.731863212585449, Spatial_g_loss: 6.4754064083099365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 27/72 [09:34<15:55, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1322/20000, Temporal_d_loss: 37.05622024536133 , Temporal_g_loss: 7.904451179504394   , Spatial_d_loss: 11.730049514770508, Spatial_g_loss: 6.639264822006226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 28/72 [09:55<15:32, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1323/20000, Temporal_d_loss: 35.57593460083008 , Temporal_g_loss: 10.417744731903076   , Spatial_d_loss: 11.761511039733886, Spatial_g_loss: 8.729548168182372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 29/72 [10:17<15:10, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1324/20000, Temporal_d_loss: 36.77012901306152 , Temporal_g_loss: 8.626667976379395   , Spatial_d_loss: 11.740164279937744, Spatial_g_loss: 7.3255295753479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/72 [10:38<14:49, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1325/20000, Temporal_d_loss: 36.54013805389404 , Temporal_g_loss: 8.764720726013184   , Spatial_d_loss: 11.702214908599853, Spatial_g_loss: 7.737096357345581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31/72 [10:59<14:28, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1326/20000, Temporal_d_loss: 31.249184226989748 , Temporal_g_loss: 8.025011444091797   , Spatial_d_loss: 11.711355400085449, Spatial_g_loss: 6.6808778762817385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/72 [11:20<14:07, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1327/20000, Temporal_d_loss: 30.614748573303224 , Temporal_g_loss: 9.789154243469238   , Spatial_d_loss: 11.712092685699464, Spatial_g_loss: 8.241265106201173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/72 [11:41<13:47, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1328/20000, Temporal_d_loss: 33.22865467071533 , Temporal_g_loss: 7.949190139770508   , Spatial_d_loss: 11.715083694458007, Spatial_g_loss: 6.705519008636474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/72 [12:03<13:27, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1329/20000, Temporal_d_loss: 34.62866058349609 , Temporal_g_loss: 6.884373140335083   , Spatial_d_loss: 11.748026275634766, Spatial_g_loss: 5.780855560302735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/72 [12:24<13:07, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1330/20000, Temporal_d_loss: 34.14672718048096 , Temporal_g_loss: 7.83368763923645   , Spatial_d_loss: 11.726466655731201, Spatial_g_loss: 6.5872642517089846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 36/72 [12:45<12:45, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1331/20000, Temporal_d_loss: 38.288601303100585 , Temporal_g_loss: 8.649471664428711   , Spatial_d_loss: 11.713372230529785, Spatial_g_loss: 7.306223726272583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/72 [13:07<12:23, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1332/20000, Temporal_d_loss: 38.824578285217285 , Temporal_g_loss: 8.588440322875977   , Spatial_d_loss: 11.734869956970215, Spatial_g_loss: 7.5645726203918455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 38/72 [13:28<12:02, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1333/20000, Temporal_d_loss: 36.70932140350342 , Temporal_g_loss: 8.188829708099366   , Spatial_d_loss: 11.772021293640137, Spatial_g_loss: 6.869082927703857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/72 [13:49<11:41, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1334/20000, Temporal_d_loss: 33.39940547943115 , Temporal_g_loss: 8.718423652648926   , Spatial_d_loss: 11.75761661529541, Spatial_g_loss: 7.651587009429932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40/72 [14:10<11:20, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1335/20000, Temporal_d_loss: 39.20791854858398 , Temporal_g_loss: 9.427078914642333   , Spatial_d_loss: 11.726290416717529, Spatial_g_loss: 7.865019941329956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 41/72 [14:31<10:58, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1336/20000, Temporal_d_loss: 49.54916210174561 , Temporal_g_loss: 12.188595962524413   , Spatial_d_loss: 11.703675842285156, Spatial_g_loss: 9.462105655670166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/72 [14:53<10:36, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1337/20000, Temporal_d_loss: 33.58863773345947 , Temporal_g_loss: 8.112590789794922   , Spatial_d_loss: 11.723600578308105, Spatial_g_loss: 7.2255853652954105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/72 [15:14<10:15, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1338/20000, Temporal_d_loss: 37.16152572631836 , Temporal_g_loss: 8.92931251525879   , Spatial_d_loss: 11.74638319015503, Spatial_g_loss: 7.259240388870239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/72 [15:35<09:54, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1339/20000, Temporal_d_loss: 28.148339462280273 , Temporal_g_loss: 6.466949224472046   , Spatial_d_loss: 11.739192771911622, Spatial_g_loss: 5.72050461769104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 45/72 [15:56<09:32, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1340/20000, Temporal_d_loss: 37.105196189880374 , Temporal_g_loss: 8.801781845092773   , Spatial_d_loss: 11.710430335998534, Spatial_g_loss: 7.137242841720581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/72 [16:17<09:11, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1341/20000, Temporal_d_loss: 39.95614185333252 , Temporal_g_loss: 10.153929519653321   , Spatial_d_loss: 11.743134784698487, Spatial_g_loss: 8.268896865844727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 47/72 [16:39<08:50, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1342/20000, Temporal_d_loss: 29.11645965576172 , Temporal_g_loss: 7.796032190322876   , Spatial_d_loss: 11.748995208740235, Spatial_g_loss: 6.495660400390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 48/72 [17:00<08:29, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1343/20000, Temporal_d_loss: 34.82031402587891 , Temporal_g_loss: 8.345929908752442   , Spatial_d_loss: 11.767971801757813, Spatial_g_loss: 7.16709794998169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 49/72 [17:21<08:08, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1344/20000, Temporal_d_loss: 30.695739936828613 , Temporal_g_loss: 7.550993919372559   , Spatial_d_loss: 11.727186584472657, Spatial_g_loss: 6.455330657958984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 50/72 [17:42<07:47, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1345/20000, Temporal_d_loss: 35.340192031860354 , Temporal_g_loss: 9.263906383514405   , Spatial_d_loss: 11.700871086120605, Spatial_g_loss: 7.744831609725952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/72 [18:04<07:25, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1346/20000, Temporal_d_loss: 33.18406047821045 , Temporal_g_loss: 9.462277793884278   , Spatial_d_loss: 11.719939708709717, Spatial_g_loss: 7.872007369995117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/72 [18:25<07:05, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1347/20000, Temporal_d_loss: 37.2517484664917 , Temporal_g_loss: 10.182322216033935   , Spatial_d_loss: 11.68860216140747, Spatial_g_loss: 8.580445289611816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 53/72 [18:46<06:43, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1348/20000, Temporal_d_loss: 33.041212463378905 , Temporal_g_loss: 7.304216289520264   , Spatial_d_loss: 11.740511226654053, Spatial_g_loss: 6.361763429641724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 54/72 [19:08<06:22, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1349/20000, Temporal_d_loss: 38.06345043182373 , Temporal_g_loss: 8.633451461791992   , Spatial_d_loss: 11.726098251342773, Spatial_g_loss: 7.170538997650146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 55/72 [19:29<06:01, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1350/20000, Temporal_d_loss: 38.1252965927124 , Temporal_g_loss: 8.341004657745362   , Spatial_d_loss: 11.73012933731079, Spatial_g_loss: 7.123255491256714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 56/72 [19:50<05:40, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1351/20000, Temporal_d_loss: 27.0205659866333 , Temporal_g_loss: 7.834309244155884   , Spatial_d_loss: 11.735185718536377, Spatial_g_loss: 6.748135757446289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 57/72 [20:11<05:19, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1352/20000, Temporal_d_loss: 38.777506256103514 , Temporal_g_loss: 9.35939426422119   , Spatial_d_loss: 11.740192031860351, Spatial_g_loss: 7.669928741455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 58/72 [20:33<04:57, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1353/20000, Temporal_d_loss: 34.751639938354494 , Temporal_g_loss: 8.115401077270509   , Spatial_d_loss: 11.725189685821533, Spatial_g_loss: 7.153628730773926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 59/72 [20:54<04:36, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1354/20000, Temporal_d_loss: 46.786852073669436 , Temporal_g_loss: 11.046857738494873   , Spatial_d_loss: 11.70140266418457, Spatial_g_loss: 8.99451789855957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 60/72 [21:15<04:15, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1355/20000, Temporal_d_loss: 32.23284854888916 , Temporal_g_loss: 7.999017143249512   , Spatial_d_loss: 11.715769195556641, Spatial_g_loss: 6.8033958911895756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/72 [21:36<03:53, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1356/20000, Temporal_d_loss: 28.8976692199707 , Temporal_g_loss: 8.056812858581543   , Spatial_d_loss: 11.724549293518066, Spatial_g_loss: 7.065015697479248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62/72 [21:58<03:32, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1357/20000, Temporal_d_loss: 37.30393962860107 , Temporal_g_loss: 9.421466827392578   , Spatial_d_loss: 11.674123668670655, Spatial_g_loss: 7.777734613418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 63/72 [22:19<03:11, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1358/20000, Temporal_d_loss: 37.172030448913574 , Temporal_g_loss: 9.241799545288085   , Spatial_d_loss: 11.734107398986817, Spatial_g_loss: 7.962191534042359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 64/72 [22:40<02:49, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1359/20000, Temporal_d_loss: 28.080852508544922 , Temporal_g_loss: 7.1183398246765135   , Spatial_d_loss: 11.727884769439697, Spatial_g_loss: 5.901105356216431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 65/72 [23:01<02:28, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1360/20000, Temporal_d_loss: 29.06647357940674 , Temporal_g_loss: 7.792977380752563   , Spatial_d_loss: 11.741946411132812, Spatial_g_loss: 6.738669967651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/72 [23:23<02:07, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1361/20000, Temporal_d_loss: 30.659318733215333 , Temporal_g_loss: 8.827878379821778   , Spatial_d_loss: 11.702468967437744, Spatial_g_loss: 7.607028770446777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 67/72 [23:44<01:46, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1362/20000, Temporal_d_loss: 39.89104442596435 , Temporal_g_loss: 9.809211254119873   , Spatial_d_loss: 11.710519981384277, Spatial_g_loss: 8.10978136062622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/72 [24:05<01:24, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1363/20000, Temporal_d_loss: 37.7732213973999 , Temporal_g_loss: 11.308166027069092   , Spatial_d_loss: 11.6725172996521, Spatial_g_loss: 8.806036186218261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 69/72 [24:26<01:03, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1364/20000, Temporal_d_loss: 34.64921684265137 , Temporal_g_loss: 7.468172311782837   , Spatial_d_loss: 11.728817558288574, Spatial_g_loss: 6.781618976593018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 70/72 [24:47<00:42, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1365/20000, Temporal_d_loss: 34.535648345947266 , Temporal_g_loss: 8.172033596038819   , Spatial_d_loss: 11.732196521759032, Spatial_g_loss: 7.501468229293823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 71/72 [25:09<00:21, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1366/20000, Temporal_d_loss: 37.2562068939209 , Temporal_g_loss: 9.914624118804932   , Spatial_d_loss: 11.70737361907959, Spatial_g_loss: 8.298825740814209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [25:30<00:00, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1367/20000, Temporal_d_loss: 33.547674560546874 , Temporal_g_loss: 9.696063041687012   , Spatial_d_loss: 11.702639770507812, Spatial_g_loss: 7.972112989425659\n",
      "Epoch 19, Temporal Generator LR: 0.00022972610544680296, Temporal Discriminator LR: 2.890223334071776e-05,  Spatial Generator LR: 0.00045923910213947175, Spatial Discriminator LR: 2.890223334071776e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Already saved: 'latest_ped2.pth'.\n",
      "Epoch: 18/277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 1/72 [00:22<26:45, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1368/20000, Temporal_d_loss: 30.63515853881836 , Temporal_g_loss: 6.583540248870849   , Spatial_d_loss: 11.723884677886963, Spatial_g_loss: 5.816173076629639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 2/72 [00:43<25:28, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1369/20000, Temporal_d_loss: 39.24637584686279 , Temporal_g_loss: 9.806237030029298   , Spatial_d_loss: 11.703910446166992, Spatial_g_loss: 7.831582498550415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 3/72 [01:05<24:47, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1370/20000, Temporal_d_loss: 33.050592231750485 , Temporal_g_loss: 7.808039045333862   , Spatial_d_loss: 11.729726886749267, Spatial_g_loss: 6.391653108596802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 4/72 [01:26<24:13, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1371/20000, Temporal_d_loss: 36.93620834350586 , Temporal_g_loss: 8.162284183502198   , Spatial_d_loss: 11.748244476318359, Spatial_g_loss: 6.981485033035279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 5/72 [01:47<23:44, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1372/20000, Temporal_d_loss: 27.19131851196289 , Temporal_g_loss: 7.287420845031738   , Spatial_d_loss: 11.753722381591796, Spatial_g_loss: 6.117988872528076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 6/72 [02:08<23:20, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1373/20000, Temporal_d_loss: 34.98440704345703 , Temporal_g_loss: 9.418748474121093   , Spatial_d_loss: 11.751708793640137, Spatial_g_loss: 7.337063789367676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 7/72 [02:29<22:59, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1374/20000, Temporal_d_loss: 29.535948944091796 , Temporal_g_loss: 8.208554983139038   , Spatial_d_loss: 11.711533260345458, Spatial_g_loss: 6.805144643783569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 8/72 [02:50<22:38, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1375/20000, Temporal_d_loss: 30.284022903442384 , Temporal_g_loss: 7.0786326885223385   , Spatial_d_loss: 11.722545337677001, Spatial_g_loss: 6.355927801132202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–Ž        | 9/72 [03:12<22:17, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1376/20000, Temporal_d_loss: 42.8515100479126 , Temporal_g_loss: 11.009359073638915   , Spatial_d_loss: 11.718385982513428, Spatial_g_loss: 9.036522388458252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 10/72 [03:33<21:54, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1377/20000, Temporal_d_loss: 33.081482124328616 , Temporal_g_loss: 7.7215851783752445   , Spatial_d_loss: 11.74458179473877, Spatial_g_loss: 7.0100133419036865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 11/72 [03:54<21:32, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1378/20000, Temporal_d_loss: 34.34406757354736 , Temporal_g_loss: 9.440706634521485   , Spatial_d_loss: 11.717415618896485, Spatial_g_loss: 8.102865552902221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 12/72 [04:15<21:11, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1379/20000, Temporal_d_loss: 28.314383506774902 , Temporal_g_loss: 7.0399822235107425   , Spatial_d_loss: 11.704434680938721, Spatial_g_loss: 6.338120174407959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 13/72 [04:36<20:50, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1380/20000, Temporal_d_loss: 34.419513893127444 , Temporal_g_loss: 9.24651460647583   , Spatial_d_loss: 11.688627433776855, Spatial_g_loss: 7.565184593200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 14/72 [04:58<20:29, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1381/20000, Temporal_d_loss: 32.26931304931641 , Temporal_g_loss: 8.721866512298584   , Spatial_d_loss: 11.691403198242188, Spatial_g_loss: 7.2626307010650635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 15/72 [05:19<20:09, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1382/20000, Temporal_d_loss: 33.975060081481935 , Temporal_g_loss: 9.050307369232177   , Spatial_d_loss: 11.711276435852051, Spatial_g_loss: 7.432880878448486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 16/72 [05:40<19:48, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1383/20000, Temporal_d_loss: 36.72745246887207 , Temporal_g_loss: 8.98627529144287   , Spatial_d_loss: 11.737623691558838, Spatial_g_loss: 7.595637845993042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 17/72 [06:01<19:26, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1384/20000, Temporal_d_loss: 26.85980224609375 , Temporal_g_loss: 6.958396911621094   , Spatial_d_loss: 11.735874652862549, Spatial_g_loss: 5.872073984146118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 18/72 [06:22<19:04, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1385/20000, Temporal_d_loss: 51.254272079467775 , Temporal_g_loss: 12.08441333770752   , Spatial_d_loss: 11.666843700408936, Spatial_g_loss: 9.716530036926269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–‹       | 19/72 [06:44<18:44, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1386/20000, Temporal_d_loss: 31.620618057250976 , Temporal_g_loss: 7.121076059341431   , Spatial_d_loss: 11.727065086364746, Spatial_g_loss: 6.470941495895386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 20/72 [07:05<18:23, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1387/20000, Temporal_d_loss: 37.93799228668213 , Temporal_g_loss: 8.504467678070068   , Spatial_d_loss: 11.745125484466552, Spatial_g_loss: 7.026588201522827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 21/72 [07:26<18:02, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1388/20000, Temporal_d_loss: 33.104506492614746 , Temporal_g_loss: 8.754719066619874   , Spatial_d_loss: 11.763574504852295, Spatial_g_loss: 7.398133754730225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 22/72 [07:47<17:42, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1389/20000, Temporal_d_loss: 28.485573387145998 , Temporal_g_loss: 7.401879072189331   , Spatial_d_loss: 11.758616733551026, Spatial_g_loss: 6.443750524520874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 23/72 [08:09<17:20, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1390/20000, Temporal_d_loss: 39.88563899993896 , Temporal_g_loss: 9.130849933624267   , Spatial_d_loss: 11.743219375610352, Spatial_g_loss: 7.963555192947387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 24/72 [08:30<16:59, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1391/20000, Temporal_d_loss: 40.72022533416748 , Temporal_g_loss: 9.032246780395507   , Spatial_d_loss: 11.696513557434082, Spatial_g_loss: 7.743352937698364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 25/72 [08:51<16:37, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1392/20000, Temporal_d_loss: 37.459052658081056 , Temporal_g_loss: 8.481752014160156   , Spatial_d_loss: 11.691848182678223, Spatial_g_loss: 7.083955430984497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/72 [09:12<16:14, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1393/20000, Temporal_d_loss: 35.23955669403076 , Temporal_g_loss: 9.241125202178955   , Spatial_d_loss: 11.712111377716065, Spatial_g_loss: 8.004796886444092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 27/72 [09:33<15:54, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1394/20000, Temporal_d_loss: 35.588816452026364 , Temporal_g_loss: 7.212596035003662   , Spatial_d_loss: 11.72253589630127, Spatial_g_loss: 6.095368576049805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 28/72 [09:55<15:33, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1395/20000, Temporal_d_loss: 41.611362266540525 , Temporal_g_loss: 10.381795406341553   , Spatial_d_loss: 11.72293996810913, Spatial_g_loss: 8.606011772155762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 29/72 [10:16<15:12, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1396/20000, Temporal_d_loss: 47.01736640930176 , Temporal_g_loss: 10.62711181640625   , Spatial_d_loss: 11.681672859191895, Spatial_g_loss: 8.596848487854004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/72 [10:37<14:51, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1397/20000, Temporal_d_loss: 33.45680732727051 , Temporal_g_loss: 7.481024980545044   , Spatial_d_loss: 11.703370380401612, Spatial_g_loss: 6.443342065811157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 31/72 [10:58<14:30, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1398/20000, Temporal_d_loss: 30.863849067687987 , Temporal_g_loss: 7.505530166625976   , Spatial_d_loss: 11.72919054031372, Spatial_g_loss: 6.258737277984619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/72 [11:19<14:07, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1399/20000, Temporal_d_loss: 41.28958625793457 , Temporal_g_loss: 9.165978240966798   , Spatial_d_loss: 11.729301357269287, Spatial_g_loss: 7.86898102760315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/72 [11:41<13:46, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400/20000, Temporal_d_loss: 35.81636962890625 , Temporal_g_loss: 8.64993782043457   , Spatial_d_loss: 11.658481884002686, Spatial_g_loss: 7.301406002044677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/72 [12:02<13:26, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1401/20000, Temporal_d_loss: 33.38963241577149 , Temporal_g_loss: 6.867462253570556   , Spatial_d_loss: 11.706835174560547, Spatial_g_loss: 6.142919301986694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/72 [12:23<13:05, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1402/20000, Temporal_d_loss: 33.12726383209228 , Temporal_g_loss: 7.439811277389526   , Spatial_d_loss: 11.65083818435669, Spatial_g_loss: 6.284697532653809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 36/72 [12:44<12:44, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1403/20000, Temporal_d_loss: 38.589061164855956 , Temporal_g_loss: 9.076376247406007   , Spatial_d_loss: 11.668267917633056, Spatial_g_loss: 7.740186262130737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/72 [13:06<12:23, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1404/20000, Temporal_d_loss: 32.9486307144165 , Temporal_g_loss: 6.741718387603759   , Spatial_d_loss: 11.721984004974365, Spatial_g_loss: 6.132565116882324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 38/72 [13:27<12:02, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1405/20000, Temporal_d_loss: 30.526378059387206 , Temporal_g_loss: 8.621594619750976   , Spatial_d_loss: 11.726620388031005, Spatial_g_loss: 7.272396230697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/72 [13:48<11:41, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1406/20000, Temporal_d_loss: 34.9468713760376 , Temporal_g_loss: 10.037911796569825   , Spatial_d_loss: 11.671922588348389, Spatial_g_loss: 8.4489164352417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40/72 [14:10<11:20, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1407/20000, Temporal_d_loss: 41.466512298583986 , Temporal_g_loss: 9.66382646560669   , Spatial_d_loss: 11.707917022705079, Spatial_g_loss: 8.121691465377808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 41/72 [14:31<10:58, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1408/20000, Temporal_d_loss: 48.50271778106689 , Temporal_g_loss: 11.050225067138673   , Spatial_d_loss: 11.68410120010376, Spatial_g_loss: 8.61117992401123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/72 [14:52<10:38, 21.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1409/20000, Temporal_d_loss: 34.7582929611206 , Temporal_g_loss: 9.369696044921875   , Spatial_d_loss: 11.687266731262207, Spatial_g_loss: 8.080249881744384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/72 [15:13<10:16, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1410/20000, Temporal_d_loss: 36.23832340240479 , Temporal_g_loss: 9.383812808990479   , Spatial_d_loss: 11.727757549285888, Spatial_g_loss: 7.649482870101929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/72 [15:34<09:54, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1411/20000, Temporal_d_loss: 31.124142456054688 , Temporal_g_loss: 8.370117378234863   , Spatial_d_loss: 11.682027244567871, Spatial_g_loss: 7.345576190948487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 45/72 [15:56<09:32, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1412/20000, Temporal_d_loss: 30.034574127197267 , Temporal_g_loss: 7.695051908493042   , Spatial_d_loss: 11.697020244598388, Spatial_g_loss: 6.528673553466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/72 [16:17<09:10, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1413/20000, Temporal_d_loss: 43.377637481689455 , Temporal_g_loss: 9.94865436553955   , Spatial_d_loss: 11.743793964385986, Spatial_g_loss: 8.276680850982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 47/72 [16:38<08:50, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1414/20000, Temporal_d_loss: 27.418341636657715 , Temporal_g_loss: 6.425622177124024   , Spatial_d_loss: 11.751424407958984, Spatial_g_loss: 6.081207227706909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 48/72 [16:59<08:30, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1415/20000, Temporal_d_loss: 37.80608654022217 , Temporal_g_loss: 9.214429378509521   , Spatial_d_loss: 11.70121202468872, Spatial_g_loss: 7.8465491771698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 49/72 [17:21<08:08, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1416/20000, Temporal_d_loss: 32.48357791900635 , Temporal_g_loss: 7.292641019821167   , Spatial_d_loss: 11.720538425445557, Spatial_g_loss: 6.565612888336181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 50/72 [17:42<07:47, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1417/20000, Temporal_d_loss: 43.65847396850586 , Temporal_g_loss: 10.375335788726806   , Spatial_d_loss: 11.674639892578124, Spatial_g_loss: 8.435490703582763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/72 [18:03<07:25, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1418/20000, Temporal_d_loss: 39.83979530334473 , Temporal_g_loss: 9.998818397521973   , Spatial_d_loss: 11.728190326690674, Spatial_g_loss: 7.973664093017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/72 [18:24<07:04, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1419/20000, Temporal_d_loss: 38.59436206817627 , Temporal_g_loss: 10.032657814025878   , Spatial_d_loss: 11.746003150939941, Spatial_g_loss: 8.224963283538818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 53/72 [18:46<06:43, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1420/20000, Temporal_d_loss: 32.91760330200195 , Temporal_g_loss: 7.0486784934997555   , Spatial_d_loss: 11.686686515808105, Spatial_g_loss: 6.277172994613648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 54/72 [19:07<06:22, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1421/20000, Temporal_d_loss: 37.92196178436279 , Temporal_g_loss: 9.421718788146972   , Spatial_d_loss: 11.706343269348144, Spatial_g_loss: 7.9960634231567385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 55/72 [19:28<06:01, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1422/20000, Temporal_d_loss: 35.05797119140625 , Temporal_g_loss: 8.480576038360596   , Spatial_d_loss: 11.70426893234253, Spatial_g_loss: 7.387219953536987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 56/72 [19:49<05:39, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1423/20000, Temporal_d_loss: 33.185871315002444 , Temporal_g_loss: 8.141748952865601   , Spatial_d_loss: 11.701097965240479, Spatial_g_loss: 6.843560457229614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 57/72 [20:11<05:18, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1424/20000, Temporal_d_loss: 31.145023345947266 , Temporal_g_loss: 6.489033222198486   , Spatial_d_loss: 11.703973960876464, Spatial_g_loss: 5.778879976272583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 58/72 [20:32<04:57, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1425/20000, Temporal_d_loss: 32.492051696777345 , Temporal_g_loss: 9.412796974182129   , Spatial_d_loss: 11.693596935272216, Spatial_g_loss: 7.818852090835572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 59/72 [20:53<04:36, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1426/20000, Temporal_d_loss: 33.59914646148682 , Temporal_g_loss: 9.193122673034669   , Spatial_d_loss: 11.681669521331788, Spatial_g_loss: 8.07794713973999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 60/72 [21:14<04:15, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1427/20000, Temporal_d_loss: 33.94674243927002 , Temporal_g_loss: 8.240178155899049   , Spatial_d_loss: 11.71903953552246, Spatial_g_loss: 7.346026659011841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/72 [21:36<03:53, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1428/20000, Temporal_d_loss: 29.378070640563966 , Temporal_g_loss: 7.45795373916626   , Spatial_d_loss: 11.682426738739014, Spatial_g_loss: 6.6040098667144775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62/72 [21:57<03:32, 21.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1429/20000, Temporal_d_loss: 39.99126300811768 , Temporal_g_loss: 9.591843700408935   , Spatial_d_loss: 11.709279823303223, Spatial_g_loss: 7.853975057601929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 63/72 [22:18<03:11, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1430/20000, Temporal_d_loss: 32.41281433105469 , Temporal_g_loss: 10.070345592498779   , Spatial_d_loss: 11.709214973449708, Spatial_g_loss: 7.959683275222778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 64/72 [22:39<02:50, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1431/20000, Temporal_d_loss: 41.320968055725096 , Temporal_g_loss: 10.612857437133789   , Spatial_d_loss: 11.696778583526612, Spatial_g_loss: 8.596233940124511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 65/72 [23:01<02:28, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1432/20000, Temporal_d_loss: 45.651917457580566 , Temporal_g_loss: 10.623706817626953   , Spatial_d_loss: 11.684392738342286, Spatial_g_loss: 8.485889148712157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/72 [23:22<02:07, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1433/20000, Temporal_d_loss: 28.232557487487792 , Temporal_g_loss: 8.787683296203614   , Spatial_d_loss: 11.740907096862793, Spatial_g_loss: 7.034099149703979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 67/72 [23:43<01:45, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1434/20000, Temporal_d_loss: 40.14957141876221 , Temporal_g_loss: 10.810507106781007   , Spatial_d_loss: 11.688076400756836, Spatial_g_loss: 8.821951770782471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/72 [24:04<01:24, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1435/20000, Temporal_d_loss: 33.882034873962404 , Temporal_g_loss: 7.773229026794434   , Spatial_d_loss: 11.689908504486084, Spatial_g_loss: 7.164325714111328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 69/72 [24:25<01:03, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1436/20000, Temporal_d_loss: 33.22189197540283 , Temporal_g_loss: 9.316337299346923   , Spatial_d_loss: 11.68717565536499, Spatial_g_loss: 8.248567962646485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 70/72 [24:47<00:42, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1437/20000, Temporal_d_loss: 32.16796722412109 , Temporal_g_loss: 8.545040130615234   , Spatial_d_loss: 11.688810253143311, Spatial_g_loss: 7.348103809356689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 71/72 [25:08<00:21, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1438/20000, Temporal_d_loss: 43.08424110412598 , Temporal_g_loss: 9.290825271606446   , Spatial_d_loss: 11.707660675048828, Spatial_g_loss: 7.6638086318969725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [25:29<00:00, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1439/20000, Temporal_d_loss: 37.64381275177002 , Temporal_g_loss: 11.145673847198486   , Spatial_d_loss: 11.676266765594482, Spatial_g_loss: 8.849392890930176\n",
      "Epoch 20, Temporal Generator LR: 0.00022701840829040558, Temporal Discriminator LR: 2.8566736446495807e-05,  Spatial Generator LR: 0.00045382031896915964, Spatial Discriminator LR: 2.8566736446495807e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Already saved: 'latest_ped2.pth'.\n",
      "Epoch: 19/277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f8804c92b05d>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kaggle/working/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mprint_infor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0mWGAN_GP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/train.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, cfg, dataset, dataloader)\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0mg_loss_temporal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss_spatial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackground_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                         \u001b[0mg_loss_temporal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                         \u001b[0mg_loss_spatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#To run training from the notebook, you can invoke the main() function from train.py\n",
    "# import sys\n",
    "# sys.argv = [\n",
    "#     'train.py', \n",
    "#     '--batch_size', '4', \n",
    "#     '--dataset', 'ped2', \n",
    "#     '--resume', 'latest_ped2', \n",
    "#     '--save_interval', '1', \n",
    "#     '--val_interval', '25', \n",
    "#     '--manualseed', '-1', \n",
    "#     '--generator_iters', '20000', \n",
    "#     '--cuda', 'True'\n",
    "# ]\n",
    "# import train\n",
    "# train.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Running Evaluation from a Notebook\n",
    "You can execute the evaluation pipeline directly within your Jupyter Notebook by simulating command-line arguments and invoking the main evaluation function. This snippet sets up the necessary parameters and starts the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:10:57.866745Z",
     "iopub.status.busy": "2025-04-20T11:10:57.866419Z",
     "iopub.status.idle": "2025-04-20T11:14:21.412592Z",
     "shell.execute_reply": "2025-04-20T11:14:21.411634Z",
     "shell.execute_reply.started": "2025-04-20T11:10:57.866718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------test cfg------------------------------\n",
      "mode: test\n",
      "dataset: ped2\n",
      "img_size: (256, 256)\n",
      "root_folder: /kaggle/input/ped2-v1/\n",
      "batch_size: 5\n",
      "train_data: /kaggle/input/ped2-v1/ped2/training/frames/\n",
      "test_root_path: /kaggle/input/ped2-v1/ped2/testing/\n",
      "train_root_path: /kaggle/input/ped2-v1/ped2/training/\n",
      "test_data: /kaggle/input/ped2-v1/ped2/testing/frames/\n",
      "g_lr: 0.0002\n",
      "d_lr: 2e-05\n",
      "show_flow: False\n",
      "resume: None\n",
      "save_interval: 1\n",
      "val_interval: 25\n",
      "manualseed: -1\n",
      "generator_iters: 20000\n",
      "cuda: True\n",
      "is_local: False\n",
      "trained_model: latest_ped2\n",
      "show_curve: True\n",
      "show_heatmap: True\n",
      "\n",
      "WGAN_Stage init model.\n",
      "True\n",
      "Cuda enabled flag: True\n",
      "Detecting: [137] 137/201, 0.00 fps."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting: [149] 149/201, 0.00 fps."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting: [164] 164/201, 0.00 fps."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting: [182] 182/201, 0.00 fps."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1029: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting: [201] 201/201, 0.00 fps.\n",
      "Spatial Stream Metrics:\n",
      "Precision: 0.9163\n",
      "Recall: 0.9569\n",
      "F1_score: 0.9362\n",
      "Accuracy: 0.8930\n",
      "Pr_auc: 0.9122\n",
      "\n",
      "Temporal Stream Metrics:\n",
      "Precision: 0.9981\n",
      "Recall: 0.9642\n",
      "F1_score: 0.9809\n",
      "Accuracy: 0.9692\n",
      "Pr_auc: 0.9917\n",
      "\n",
      "Combined Stream Metrics:\n",
      "Precision: 0.9932\n",
      "Recall: 0.9684\n",
      "F1_score: 0.9806\n",
      "Accuracy: 0.9687\n",
      "Pr_auc: 0.9877\n",
      "sauc: 0.9470528482540365 | tauc: 0.9981879928123155 | cauc: 0.9969190849112267\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To run evaluation from the notebook, you can invoke the main() function from eval.py\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'eval.py', \n",
    "    '--batch_size', '5', \n",
    "    '--trained_model', 'latest_ped2', \n",
    "    '--dataset', 'ped2', \n",
    "    '--show_curve', 'True', \n",
    "    '--show_heatmap', 'True', \n",
    "    '--manualseed', '-1', \n",
    "    '--generator_iters', '20000', \n",
    "    '--cuda', 'True'\n",
    "]\n",
    "import eval\n",
    "eval.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-19T07:44:06.137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-19T07:44:06.138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "download_file('/kaggle/working/weights/latest_ped2.pth', 'out')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7115468,
     "isSourceIdPinned": false,
     "sourceId": 11367273,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
